<!DOCTYPE html>
<html lang="en"><head>
<script src="7-Multi Classifier_files/libs/quarto-html/tabby.min.js"></script>
<script src="7-Multi Classifier_files/libs/quarto-html/popper.min.js"></script>
<script src="7-Multi Classifier_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="7-Multi Classifier_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="7-Multi Classifier_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="7-Multi Classifier_files/libs/quarto-html/quarto-syntax-highlighting-cdaacfc258cb6f151192107f105ac881.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.9.12">

  <meta name="author" content="Matteo Francia   DISI — University of Bologna   m.francia@unibo.it">
  <title>Machine Learning and Data Mining (Module 2)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="7-Multi Classifier_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="7-Multi Classifier_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="7-Multi Classifier_files/libs/revealjs/dist/theme/quarto-b3aa9dda08c8fde6dffd4aadb76df7d0.css">
  <link href="7-Multi Classifier_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="7-Multi Classifier_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="7-Multi Classifier_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="7-Multi Classifier_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Machine Learning and Data Mining (Module 2)</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Matteo Francia <br> DISI — University of Bologna <br> m.francia@unibo.it 
</div>
</div>
</div>

</section>
<section id="data-mining" class="title-slide slide level1 center">
<h1>Data Mining</h1>

</section>

<section id="multi-classifier" class="title-slide slide level1 center">
<h1>Multi classifier</h1>

<img data-src="img/multi/7-Multi%20Classifier_0.png" class="r-stretch"><p><strong>Matteo Golfarelli</strong></p>
</section>

<section id="basics" class="title-slide slide level1 center">
<h1>Basics</h1>
<ul>
<li>Construct multiple base classifiers and predict the class to which a record belongs by aggregating the classifications obtained
<ul>
<li>The result of the compound classifier is defined by means of a function that, for example, assigns the record to the class that was “voted” by the largest number of classifiers</li>
</ul></li>
</ul>
</section>

<section id="bayes-theorem-an-example" class="title-slide slide level1 center">
<h1>Bayes Theorem: an example</h1>
<ul>
<li>Suppose we have 25 simple classifiers.
<ul>
<li>Each classifier has an error-rate of  = 0.35</li>
<li>Assume that the classifiers are independent</li>
</ul></li>
<li>There is no correlation between the error-rates of the classifiers</li>
<li>The probability that the compound classifier gives an incorrect result is:</li>
<li>Necessary conditions for the compound classifier to give better results than the simple classifiers are:
<ul>
<li>That the classifiers are independent</li>
<li>That the error-rate of the single classifier is less than 0.5 Let us suppose</li>
</ul></li>
</ul>
</section>

<section id="how-to-build-a-composite-classifier" class="title-slide slide level1 center">
<h1>How to build a composite classifier</h1>
<ul>
<li><strong>Changing the training set: building more training sets from the given data set</strong>
<ul>
<li>Bagging and Boosting</li>
</ul></li>
</ul>
</section>

<section id="how-to-build-a-composite-classifier-cont." class="title-slide slide level1 center">
<h1>How to build a composite classifier (cont.)</h1>
<ul>
<li><strong>Changing the training set: building more training sets from the given data set</strong>
<ul>
<li>Bagging and Boosting</li>
</ul></li>
<li><strong>By changing the attributes used: individual classifiers are based on a subset of the attributes</strong>
<ul>
<li>Useful when attributes are highly redundant  Random Forest</li>
</ul></li>
</ul>
</section>

<section id="how-to-build-a-composite-classifier-cont.-1" class="title-slide slide level1 center">
<h1>How to build a composite classifier (cont.)</h1>
<ul>
<li><strong>Changing the training set: building more training sets from the given data set</strong>
<ul>
<li>Bagging and Boosting</li>
</ul></li>
<li><strong>By changing the attributes used: individual classifiers are based on a subset of the attributes</strong>
<ul>
<li>Useful when attributes are highly redundant  Random Forest</li>
</ul></li>
<li><strong>Changing the classes considered: </strong>
<ul>
<li>Partition the classes into two groups A0 and A1 and transforms the given problem into a binary problem. The classes that belong to A0 are classified as 0 the remaining ones as 1.</li>
<li>The different classifiers are constructed by resubdividing the classes into different subsets</li>
<li>The classification of the composite classifier is obtained by increasing the score of the classes that belong to the chosen subset by 1.</li>
<li>The record is finally assigned to the class that obtains the highest score</li>
<li>Error-Correcting Output Coding: translates a multi-class classification problem into a binary classification one</li>
</ul></li>
</ul>
</section>

<section id="how-to-build-a-composite-classifier-cont.-2" class="title-slide slide level1 center">
<h1>How to build a composite classifier (cont.)</h1>
<ul>
<li><strong>Changing the training set: building more training sets from the given data set</strong>
<ul>
<li>Bagging and Boosting</li>
</ul></li>
<li><strong>By changing the attributes used: individual classifiers are based on a subset of the attributes</strong>
<ul>
<li>Useful when attributes are highly redundant  Random Forest</li>
</ul></li>
<li><strong>Changing the classes considered: </strong>
<ul>
<li>One partitions the classes into two groups A0 and A1 and transforms the given problem into a binary problem. The classes that belong to A0 are classified as 0 the remaining ones as 1.</li>
<li>The different classifiers are constructed by resubdividing the classes into different subsets</li>
<li>The classification of the composite classifier is obtained by increasing the score of the classes that belong to the chosen subset by 1.</li>
<li>The record is finally assigned to the class that obtains the highest score</li>
<li>Error-Correcting Output Coding: translates a multi-class classification problem into a binary classification one</li>
</ul></li>
<li><strong>Changing the parameters of the learning algorithm:</strong>
<ul>
<li>Topology and weights of a neural network</li>
<li>Decision trees with random choice policies of the attributes to be used</li>
</ul></li>
</ul>
</section>

<section id="error-decomposition-bias-variance-noise" class="title-slide slide level1 center">
<h1>Error Decomposition: Bias, Variance &amp; Noise</h1>
<ul>
<li>A formal model for analyzing the error made by a classifier
<ul>
<li>Probability of a classifier making a mistake in its prediction</li>
</ul></li>
<li>The error committed by a classifier depends on:
<ul>
<li><strong>BIAS</strong> : ability of the chosen classifier in modeling events and extending the prediction to events not in the training set
<ul>
<li>Different types of classifiers have different capabilities in defining decision boundary between classes</li>
<li>For example, different decision trees may have different capabilities</li>
</ul></li>
<li><strong>VARIANCE</strong> : capability of the training set in representing the actual data set
<ul>
<li>Different training sets may result in different decision boundary</li>
</ul></li>
<li><strong>NOISE</strong> : non-determinism of the classes to be determined
<ul>
<li>Set instances with the same attribute values may result in different classes</li>
</ul></li>
</ul></li>
</ul>
<p><img data-src="img/multi/7-Multi%20Classifier_1.png"></p>
<p><img data-src="img/multi/7-Multi%20Classifier_2.png"></p>
</section>

<section id="error-decomposition-bias-variance-noise-cont." class="title-slide slide level1 center">
<h1>Error Decomposition: Bias, Variance &amp; Noise (cont.)</h1>
<ul>
<li>Different types of classifiers have inherently different capabilities in modeling the edges of regions
<ul>
<li>100 training sets each containing 100 examples obtained from a predefined region partition (dashed line)</li>
<li>The black line represents the average true line of separation obtained from the 100 classifiers</li>
</ul></li>
<li>The difference between the true separation line and the average separation line represents the classifier bias
<ul>
<li>The bias of the 1-NN is lower</li>
<li>However, k-NNs are more sensitive to the composition of the training set and therefore will exhibit greater variance</li>
</ul></li>
</ul>

<img data-src="img/multi/7-Multi%20Classifier_3.png" class="r-stretch"></section>

<section id="multi-classifier-1" class="title-slide slide level1 center">
<h1>Multi classifier</h1>
<ul>
<li>Different classifiers (e.g., Decision trees + k-nearest neighbor) are used to reduce error bias
<ul>
<li>Classifiers must be independent: no (or little) correlation between errors made between two classifiers</li>
<li>Different classifiers can operate on distinct subsets of <em>attributes </em> on which they have ideal performance</li>
</ul></li>
<li>Class membership is decided by a voting mechanism
<ul>
<li>Class voted on by the largest number of classifiers</li>
<li>Voting can be weighted according to the confidence of the classifier in case the classifier provides it</li>
<li>Ex. C1 classifier votes for class X. In training C1 made 25 out of 100 errors for class X. Classifier C2 votes for class Y. In training phase C2 committed 10 out of 100 errors for class Y.</li>
<li><strong>The record is assigned to class Y</strong></li>
</ul></li>
</ul>
</section>

<section id="bagging" class="title-slide slide level1 center">
<h1>Bagging</h1>
<ul>
<li>Allows the construction of compound classifiers that associate an event with the highest rated class from the base classifiers</li>
<li>Each classifier is constructed by <strong>bootstrapping</strong> the same training set</li>
<li>// <em>k </em> = number of boostrap cycles <em>N</em> = training set cardinality</li>
<li>// ()=1 if the argument is TRUE, 0 otherwise</li>
<li>__ for __ <em>i</em> =1 to <em>k </em> <strong>do</strong></li>
<li>Create a training set <em>D</em> <em>i</em> such that | <em>D</em> <em>i</em> |= <em>N</em></li>
<li>Train a classifier <em>C</em> <em>i</em> using <em>D</em> <em>i</em></li>
<li>__ end for__</li>
<li>Bagging improves generalization error by reducing the <strong>variance</strong> component
<ul>
<li>Thus, bagging will be particularly useful for those types of classifiers that are sensitive to changes in the training set</li>
</ul></li>
</ul>
</section>

<section id="bagging-cont." class="title-slide slide level1 center">
<h1>Bagging (cont.)</h1>
<ul>
<li>Allows the construction of compound classifiers that associate an event with the highest rated class from the base classifiers</li>
<li>Each classifier is constructed by <strong>bootstrapping</strong> the same training set</li>
<li>// <em>k </em> = number of boostrap cycles <em>N</em> = training set cardinality</li>
<li>// ()=1 if the argument is TRUE, 0 otherwise</li>
<li>__ for __ <em>i</em> =1 to <em>k </em> <strong>do</strong></li>
<li>Create a training set <em>D</em> <em>i</em> such that | <em>D</em> <em>i</em> |= <em>N</em></li>
<li>Train a classifier <em>C</em> <em>i</em> using <em>D</em> <em>i</em></li>
<li>__ end for__</li>
<li>Bagging improves generalization error by reducing the <strong>variance</strong> component
<ul>
<li>Thus, bagging will be particularly useful for those types of classifiers that are sensitive to changes in the training set</li>
</ul></li>
</ul>
<p>In statistics: any test or metric that uses random sampling with replacement</p>
</section>

<section id="bagging-an-example" class="title-slide slide level1 center">
<h1>Bagging: an example</h1>
<ul>
<li>Basic classifier: one-level binary decision tree
<ul>
<li>Can only make choices of the type x  s  -1 x&gt;s  1 where s is the split point</li>
</ul></li>
<li>The data set</li>
<li>Accuracy of the basic classifier cannot exceed 70%
<ul>
<li>x  0.3  1 x&gt;0.3  -1</li>
<li>x  0.7  -1 x&gt;0.7  1</li>
</ul></li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;"><em>x</em></th>
<th style="text-align: center;">0.1</th>
<th style="text-align: center;">0.2</th>
<th style="text-align: center;">0.3</th>
<th style="text-align: center;">0.4</th>
<th style="text-align: center;">0.5</th>
<th style="text-align: center;">0.6</th>
<th style="text-align: center;">0.7</th>
<th style="text-align: center;">0.8</th>
<th style="text-align: center;">0.9</th>
<th style="text-align: center;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>y</em></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</section>

<section id="bagging-cycles" class="title-slide slide level1 center">
<h1>Bagging cycles</h1>

<img data-src="img/multi/7-Multi%20Classifier_4.png" class="r-stretch"></section>

<section id="bagging-result" class="title-slide slide level1 center">
<h1>Bagging result</h1>
<p>Bagging determines the behavior of a two-level decision tree</p>

<img data-src="img/multi/7-Multi%20Classifier_5.png" class="r-stretch"><p><em>Draw</em> _ the _ <em>two</em> <em>-level </em> <em>decision</em> _ _ <em>tree</em> _ _ <em>corresponding</em> _ to the result of _ <em>bagging</em></p>
</section>

<section id="random-forest" class="title-slide slide level1 center">
<h1>Random Forest</h1>

</section>

<section id="boosting" class="title-slide slide level1 center">
<h1>Boosting</h1>
<ul>
<li>An iterative approach to progressively adjust the composition of the training set in order to focus on incorrectly classified records</li>
<li>Initially, all N records have the same weight (1/N)</li>
<li>Unlike bagging, the weights can change at the end of the boosting round in order to increase the probability of the record being selected in the training set
<ul>
<li>The probability of records that are difficult to classify i.e., that were classified incorrectly in the previous boosting round are increased</li>
</ul></li>
<li>The final result is obtained by combining the predictions made by the different classifiers</li>
<li>Boosting techniques differ based on how:</li>
<li>the weights of the training set records are updated</li>
<li>the predictions of the classifiers are combined</li>
<li><strong>AdaBoost </strong> is one of the most widely used boosting techniques</li>
</ul>
</section>

<section id="adaboost" class="title-slide slide level1 center">
<h1>AdaBoost</h1>
<ul>
<li>Let <em>C</em> 1, <em>C</em> 2, …, <em>C</em> <em>T</em> _ _ be the basic <em>T</em> classifiers each used at a boost cycle <em>j</em>  [1, <em>T</em> ]. Let <em></em> <em>j</em> be the error rate:</li>
<li>( <em>x</em> <em>i</em> ,y <em>i</em> ) i=1..N records of the training set</li>
<li><em>w</em> <em>i</em> is the weight of the i-th element of the training set</li>
<li>()=1 if the argument is TRUE, 0 otherwise</li>
<li>The relevance of a classifier is defined as:</li>
<li> <em>j</em> takes positive values when the error rate is close to 0</li>
<li> <em>j</em> takes negative values when the error rate is close to 1</li>
</ul>

<img data-src="img/multi/7-Multi%20Classifier_7.png" class="r-stretch"></section>

<section id="adaboost-cont." class="title-slide slide level1 center">
<h1>AdaBoost (cont.)</h1>
<ul>
<li>The weight updating rule for record <em>i</em> at boosting cycle <em>j </em> is</li>
<li><em>Z</em> <em>j</em> is a normalization factor to ensure that</li>
<li>The weight of correctly classified records is reduced,</li>
<li>that of weights classified incorrectly increases</li>
<li>If a boost cycle produces a classifier with error rate greater than 50%, the weights are reported 1/n</li>
<li>The record is assigned to the class that maximizes the weighted sum:</li>
</ul>
</section>

<section id="adaboost-cont.-1" class="title-slide slide level1 center">
<h1>AdaBoost (cont.)</h1>
<p><strong>w</strong> ={ <em>w</em> <em>i</em> =1/N <em>i</em> =1..N}</p>
<p><strong>for </strong> <em>j</em> =1 to T _ _ <strong>do</strong> // boost __ __ cycle number</p>
<p>Build a training set D <em>j</em> by sampling with replacement based on <strong>w</strong></p>
<p>Train a classifier C <em>j</em> on D <em>j</em></p>
<p>Apply C <em>j</em> to D</p>
<p>_ _ <em>j</em> =1/N  <em>i</em> <em>w</em> <em>i</em> (C <em>j</em> ( <strong>x</strong> i) <em>y</em> <em>i</em> ) // compute the weighted error</p>
<p>__ if__ <em></em> <em>j </em> &gt; 0.5 <strong>then </strong></p>
<p><strong>w</strong> ={ <em>w</em> <em>i</em> =1/N| <em>i</em> =1,2,…,N}; // reset!</p>
<p>__ else__</p>
<p>_ _ <em>j</em> =1/2 ln((1- <em></em> <em>j</em> )/ <em></em> <em>j</em> );</p>
<p>Update the weight <strong>w;</strong></p>
<p>__ end if;__</p>
<p><strong>end for;</strong></p>
<p>__ __ // sign return 1/-1 if the classification is correct/wrong</p>
</section>

<section id="adaboost-an-example" class="title-slide slide level1 center">
<h1>AdaBoost: an example</h1>
<ul>
<li>Basic classifier: one-level binary decision tree
<ul>
<li>Can only make choices of the type x  s  -1 x&gt;s  1 where s is the split point</li>
</ul></li>
<li>The data set</li>
<li>Accuracy of the basic classifier cannot exceed 70%
<ul>
<li>x  0.3  1 x&gt;0.3  -1</li>
<li>x  0.7  -1 x&gt;0.7  1</li>
</ul></li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;"><em>x</em></th>
<th style="text-align: center;">0.1</th>
<th style="text-align: center;">0.2</th>
<th style="text-align: center;">0.3</th>
<th style="text-align: center;">0.4</th>
<th style="text-align: center;">0.5</th>
<th style="text-align: center;">0.6</th>
<th style="text-align: center;">0.7</th>
<th style="text-align: center;">0.8</th>
<th style="text-align: center;">0.9</th>
<th style="text-align: center;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>y</em></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</section>

<section id="adaboost-cycles" class="title-slide slide level1 center">
<h1>AdaBoost: cycles</h1>

<img data-src="img/multi/7-Multi%20Classifier_8.png" class="r-stretch"></section>

<section id="adaboost-cycles-cont." class="title-slide slide level1 center">
<h1>AdaBoost: cycles (cont.)</h1>

<img data-src="img/multi/7-Multi%20Classifier_9.png" class="r-stretch"><p>Split point: 0.75</p>
<p><em></em> 1 _ _ =0.03</p>
<p><em></em> 1=1.738</p>
<p>Split point: 0.05</p>
<p><em></em> 2 _ _ =0.004</p>
<p><em></em> 2=2.7784</p>
<p>Split point: 0.30</p>
<p><em></em> 3 _ _ =0.00027</p>
<p><em></em> 3=4.1195</p>
</section>

<section id="adaboost-an-example-1" class="title-slide slide level1 center">
<h1>AdaBoost: an example</h1>
<ul>
<li>The dataset</li>
<li>The result
<ul>
<li>5.16 = -1.738 + 2.7784 + 4.1195</li>
<li>The classifier does not make errors adopting a behvior compatible with a two-level decision tree</li>
</ul></li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;"><em>x</em></th>
<th style="text-align: center;">0.1</th>
<th style="text-align: center;">0.2</th>
<th style="text-align: center;">0.3</th>
<th style="text-align: center;">0.4</th>
<th style="text-align: center;">0.5</th>
<th style="text-align: center;">0.6</th>
<th style="text-align: center;">0.7</th>
<th style="text-align: center;">0.8</th>
<th style="text-align: center;">0.9</th>
<th style="text-align: center;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>y</em></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>

<img data-src="img/multi/7-Multi%20Classifier_10.png" class="r-stretch"><p><em></em> 1=1.738</p>
<p><em></em> 2=2.7784</p>
<p><em></em> 3=4.1195</p>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Matteo Francia - Machine Learning and Data Mining (Module 2) - A.Y. 2025/26</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="7-Multi Classifier_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="7-Multi Classifier_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="7-Multi Classifier_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="7-Multi Classifier_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="7-Multi Classifier_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="7-Multi Classifier_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="7-Multi Classifier_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="7-Multi Classifier_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="7-Multi Classifier_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="7-Multi Classifier_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': true,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>