<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="lab-09-breastcancer.solution_files/libs/quarto-html/tabby.min.js"></script>
<script src="lab-09-breastcancer.solution_files/libs/quarto-html/popper.min.js"></script>
<script src="lab-09-breastcancer.solution_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="lab-09-breastcancer.solution_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="lab-09-breastcancer.solution_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="lab-09-breastcancer.solution_files/libs/quarto-html/quarto-syntax-highlighting-cdaacfc258cb6f151192107f105ac881.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.9.12">

  <meta name="author" content="Matteo Francia   DISI — University of Bologna   m.francia@unibo.it">
  <title>Machine Learning and Data Mining (Module 2)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="lab-09-breastcancer.solution_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="lab-09-breastcancer.solution_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="lab-09-breastcancer.solution_files/libs/revealjs/dist/theme/quarto-b3aa9dda08c8fde6dffd4aadb76df7d0.css">
  <link href="lab-09-breastcancer.solution_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="lab-09-breastcancer.solution_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="lab-09-breastcancer.solution_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="lab-09-breastcancer.solution_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Machine Learning and Data Mining (Module 2)</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Matteo Francia <br> DISI — University of Bologna <br> m.francia@unibo.it 
</div>
</div>
</div>

</section>
<section class="slide level2">

<p><a href="https://colab.research.google.com/github/w4bo/AA2526-unibo-mldm/blob/master/slides/lab-09-breastcancer.solution.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
</section>
<section id="the-breastcancer-challenge" class="title-slide slide level1 center">
<h1>The <code>BreastCancer</code> challenge</h1>
<p><strong>Goal</strong>: it is your job to predict the <code>diagnosis</code> for each data item.</p>
<p><strong>Metric</strong>: submissions are evaluated using the accuracy score.</p>
<ul>
<li>When splitting train and test datasets, the test dataset should contain 30% of the data.</li>
</ul>
<p><strong>Requirements</strong>: you are allowed to use <code>numpy</code>, <code>pandas</code>, <code>matplotlib</code>, <code>sns</code>, and <code>sklearn</code> Python libraries.</p>
<ol type="1">
<li>You can import any model from <code>sk-learn</code>.</li>
<li>Try <code>sk-learn</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">pipelines</a></li>
<li>Explore AutoML with <code>FLAML</code></li>
</ol>
</section>

<section id="setup" class="title-slide slide level1 center">
<h1>Setup</h1>
<div id="cell-4" class="cell" data-execution_count="2">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="co"># Import the libraries used for machine learning</span></span>
<span id="cb1-2"><a href=""></a><span class="im">import</span> numpy <span class="im">as</span> np  <span class="co"># linear algebra</span></span>
<span id="cb1-3"><a href=""></a><span class="im">import</span> pandas <span class="im">as</span> pd  <span class="co"># data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL</span></span>
<span id="cb1-4"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  <span class="co"># used for plotting </span></span>
<span id="cb1-5"><a href=""></a><span class="im">import</span> seaborn <span class="im">as</span> sns   <span class="co"># used for plotting</span></span>
<span id="cb1-6"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split  <span class="co">#  split the data into training and test</span></span>
<span id="cb1-7"><a href=""></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier  <span class="co"># import a machine learning model</span></span>
<span id="cb1-8"><a href=""></a><span class="im">from</span> sklearn <span class="im">import</span> metrics  <span class="co"># check the error and accuracy of the model</span></span>
<span id="cb1-9"><a href=""></a></span>
<span id="cb1-10"><a href=""></a><span class="co"># SEED all random generators</span></span>
<span id="cb1-11"><a href=""></a><span class="im">import</span> random</span>
<span id="cb1-12"><a href=""></a><span class="im">import</span> os</span>
<span id="cb1-13"><a href=""></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb1-14"><a href=""></a>random.seed(seed)</span>
<span id="cb1-15"><a href=""></a>os.environ[<span class="st">'PYTHONHASHSEED'</span>] <span class="op">=</span> <span class="bu">str</span>(seed)</span>
<span id="cb1-16"><a href=""></a>np.random.seed(seed)</span>
<span id="cb1-17"><a href=""></a></span>
<span id="cb1-18"><a href=""></a><span class="co"># read the data</span></span>
<span id="cb1-19"><a href=""></a>df <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/w4bo/teaching-handsondatapipelines/main/materials/datasets/breastcancer.csv"</span>)</span></code></pre></div>
</details>
</div>
</section>

<section id="data-understanding" class="title-slide slide level1 center">
<h1>Data understanding</h1>
<p>Hints</p>
<ul>
<li>There are 569 observations with 30 features each</li>
<li>Each observation is labelled with a <code>diagnosis</code></li>
</ul>
<div id="cell-6" class="cell" data-execution_count="3">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb2-1"><a href=""></a>df</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">diagnosis</th>
<th data-quarto-table-cell-role="th">radius_mean</th>
<th data-quarto-table-cell-role="th">texture_mean</th>
<th data-quarto-table-cell-role="th">perimeter_mean</th>
<th data-quarto-table-cell-role="th">area_mean</th>
<th data-quarto-table-cell-role="th">smoothness_mean</th>
<th data-quarto-table-cell-role="th">compactness_mean</th>
<th data-quarto-table-cell-role="th">concavity_mean</th>
<th data-quarto-table-cell-role="th">concave points_mean</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">texture_worst</th>
<th data-quarto-table-cell-role="th">perimeter_worst</th>
<th data-quarto-table-cell-role="th">area_worst</th>
<th data-quarto-table-cell-role="th">smoothness_worst</th>
<th data-quarto-table-cell-role="th">compactness_worst</th>
<th data-quarto-table-cell-role="th">concavity_worst</th>
<th data-quarto-table-cell-role="th">concave points_worst</th>
<th data-quarto-table-cell-role="th">symmetry_worst</th>
<th data-quarto-table-cell-role="th">fractal_dimension_worst</th>
<th data-quarto-table-cell-role="th">Unnamed: 32</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>842302</td>
<td>M</td>
<td>17.99</td>
<td>10.38</td>
<td>122.80</td>
<td>1001.0</td>
<td>0.11840</td>
<td>0.27760</td>
<td>0.30010</td>
<td>0.14710</td>
<td>...</td>
<td>17.33</td>
<td>184.60</td>
<td>2019.0</td>
<td>0.16220</td>
<td>0.66560</td>
<td>0.7119</td>
<td>0.2654</td>
<td>0.4601</td>
<td>0.11890</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>842517</td>
<td>M</td>
<td>20.57</td>
<td>17.77</td>
<td>132.90</td>
<td>1326.0</td>
<td>0.08474</td>
<td>0.07864</td>
<td>0.08690</td>
<td>0.07017</td>
<td>...</td>
<td>23.41</td>
<td>158.80</td>
<td>1956.0</td>
<td>0.12380</td>
<td>0.18660</td>
<td>0.2416</td>
<td>0.1860</td>
<td>0.2750</td>
<td>0.08902</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>84300903</td>
<td>M</td>
<td>19.69</td>
<td>21.25</td>
<td>130.00</td>
<td>1203.0</td>
<td>0.10960</td>
<td>0.15990</td>
<td>0.19740</td>
<td>0.12790</td>
<td>...</td>
<td>25.53</td>
<td>152.50</td>
<td>1709.0</td>
<td>0.14440</td>
<td>0.42450</td>
<td>0.4504</td>
<td>0.2430</td>
<td>0.3613</td>
<td>0.08758</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>84348301</td>
<td>M</td>
<td>11.42</td>
<td>20.38</td>
<td>77.58</td>
<td>386.1</td>
<td>0.14250</td>
<td>0.28390</td>
<td>0.24140</td>
<td>0.10520</td>
<td>...</td>
<td>26.50</td>
<td>98.87</td>
<td>567.7</td>
<td>0.20980</td>
<td>0.86630</td>
<td>0.6869</td>
<td>0.2575</td>
<td>0.6638</td>
<td>0.17300</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>84358402</td>
<td>M</td>
<td>20.29</td>
<td>14.34</td>
<td>135.10</td>
<td>1297.0</td>
<td>0.10030</td>
<td>0.13280</td>
<td>0.19800</td>
<td>0.10430</td>
<td>...</td>
<td>16.67</td>
<td>152.20</td>
<td>1575.0</td>
<td>0.13740</td>
<td>0.20500</td>
<td>0.4000</td>
<td>0.1625</td>
<td>0.2364</td>
<td>0.07678</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">...</th>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">564</th>
<td>926424</td>
<td>M</td>
<td>21.56</td>
<td>22.39</td>
<td>142.00</td>
<td>1479.0</td>
<td>0.11100</td>
<td>0.11590</td>
<td>0.24390</td>
<td>0.13890</td>
<td>...</td>
<td>26.40</td>
<td>166.10</td>
<td>2027.0</td>
<td>0.14100</td>
<td>0.21130</td>
<td>0.4107</td>
<td>0.2216</td>
<td>0.2060</td>
<td>0.07115</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">565</th>
<td>926682</td>
<td>M</td>
<td>20.13</td>
<td>28.25</td>
<td>131.20</td>
<td>1261.0</td>
<td>0.09780</td>
<td>0.10340</td>
<td>0.14400</td>
<td>0.09791</td>
<td>...</td>
<td>38.25</td>
<td>155.00</td>
<td>1731.0</td>
<td>0.11660</td>
<td>0.19220</td>
<td>0.3215</td>
<td>0.1628</td>
<td>0.2572</td>
<td>0.06637</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">566</th>
<td>926954</td>
<td>M</td>
<td>16.60</td>
<td>28.08</td>
<td>108.30</td>
<td>858.1</td>
<td>0.08455</td>
<td>0.10230</td>
<td>0.09251</td>
<td>0.05302</td>
<td>...</td>
<td>34.12</td>
<td>126.70</td>
<td>1124.0</td>
<td>0.11390</td>
<td>0.30940</td>
<td>0.3403</td>
<td>0.1418</td>
<td>0.2218</td>
<td>0.07820</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">567</th>
<td>927241</td>
<td>M</td>
<td>20.60</td>
<td>29.33</td>
<td>140.10</td>
<td>1265.0</td>
<td>0.11780</td>
<td>0.27700</td>
<td>0.35140</td>
<td>0.15200</td>
<td>...</td>
<td>39.42</td>
<td>184.60</td>
<td>1821.0</td>
<td>0.16500</td>
<td>0.86810</td>
<td>0.9387</td>
<td>0.2650</td>
<td>0.4087</td>
<td>0.12400</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">568</th>
<td>92751</td>
<td>B</td>
<td>7.76</td>
<td>24.54</td>
<td>47.92</td>
<td>181.0</td>
<td>0.05263</td>
<td>0.04362</td>
<td>0.00000</td>
<td>0.00000</td>
<td>...</td>
<td>30.37</td>
<td>59.16</td>
<td>268.6</td>
<td>0.08996</td>
<td>0.06444</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.2871</td>
<td>0.07039</td>
<td>NaN</td>
</tr>
</tbody>
</table>

<p>569 rows × 33 columns</p>
</div>
</div>
</div>
</section>

<section id="data-profiling" class="title-slide slide level1 center">
<h1>Data profiling</h1>
<div id="cell-8" class="cell" data-execution_count="4">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb3-1"><a href=""></a>df.info()</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 569 entries, 0 to 568
Data columns (total 33 columns):
 #   Column                   Non-Null Count  Dtype  
---  ------                   --------------  -----  
 0   id                       569 non-null    int64  
 1   diagnosis                569 non-null    object 
 2   radius_mean              569 non-null    float64
 3   texture_mean             569 non-null    float64
 4   perimeter_mean           569 non-null    float64
 5   area_mean                569 non-null    float64
 6   smoothness_mean          569 non-null    float64
 7   compactness_mean         569 non-null    float64
 8   concavity_mean           569 non-null    float64
 9   concave points_mean      569 non-null    float64
 10  symmetry_mean            569 non-null    float64
 11  fractal_dimension_mean   569 non-null    float64
 12  radius_se                569 non-null    float64
 13  texture_se               569 non-null    float64
 14  perimeter_se             569 non-null    float64
 15  area_se                  569 non-null    float64
 16  smoothness_se            569 non-null    float64
 17  compactness_se           569 non-null    float64
 18  concavity_se             569 non-null    float64
 19  concave points_se        569 non-null    float64
 20  symmetry_se              569 non-null    float64
 21  fractal_dimension_se     569 non-null    float64
 22  radius_worst             569 non-null    float64
 23  texture_worst            569 non-null    float64
 24  perimeter_worst          569 non-null    float64
 25  area_worst               569 non-null    float64
 26  smoothness_worst         569 non-null    float64
 27  compactness_worst        569 non-null    float64
 28  concavity_worst          569 non-null    float64
 29  concave points_worst     569 non-null    float64
 30  symmetry_worst           569 non-null    float64
 31  fractal_dimension_worst  569 non-null    float64
 32  Unnamed: 32              0 non-null      float64
dtypes: float64(31), int64(1), object(1)
memory usage: 146.8+ KB</code></pre>
</div>
</div>
</section>

<section id="feature-semantics" class="title-slide slide level1 center">
<h1>Feature semantics</h1>
<p>Hint:</p>
<ul>
<li><code>id</code> of the observation</li>
<li><code>diagnosis</code> (M = malignant, B = benign)</li>
<li>Ten real-valued features are computed for each cell nucleus:
<ul>
<li><code>radius</code> (mean of distances from center to points on the perimeter)</li>
<li><code>texture</code> (standard deviation of gray-scale values)</li>
<li><code>perimeter</code></li>
<li><code>area</code></li>
<li><code>smoothness</code> (local variation in radius lengths)</li>
<li><code>compactness</code> (perimeter^2 / area - 1.0)</li>
<li><code>concavity</code> (severity of concave portions of the contour)</li>
<li><code>concave</code> points (number of concave portions of the contour)</li>
<li><code>symmetry</code></li>
<li><code>fractal dimension</code> (“coastline approximation” - 1)</li>
</ul></li>
</ul>
<p><code>*_mean</code>: the means of all cells</p>
<p><code>*_se</code>: standard error of all cells</p>
<p><code>*_worst</code>: the worst cell</p>
</section>

<section id="and-now" class="title-slide slide level1 center">
<h1>… and now?</h1>
<p>Take a first glance to the dataset</p>
<ul>
<li>Do we consider all features?</li>
<li>Are there null values?</li>
<li>Which are the attribute types?</li>
<li>Which are the attribute ranges?</li>
<li>How many labels?</li>
<li>Are classes unbalanced?</li>
<li>Check the attribute’s distribution</li>
<li>Check the relationships between attributes (e.g., the correlation). Should we keep all attributes?</li>
</ul>
</section>

<section id="data-distribution" class="title-slide slide level1 center">
<h1>Data distribution</h1>
<div id="cell-12" class="cell" data-execution_count="5">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb5-1"><a href=""></a>df.describe()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">radius_mean</th>
<th data-quarto-table-cell-role="th">texture_mean</th>
<th data-quarto-table-cell-role="th">perimeter_mean</th>
<th data-quarto-table-cell-role="th">area_mean</th>
<th data-quarto-table-cell-role="th">smoothness_mean</th>
<th data-quarto-table-cell-role="th">compactness_mean</th>
<th data-quarto-table-cell-role="th">concavity_mean</th>
<th data-quarto-table-cell-role="th">concave points_mean</th>
<th data-quarto-table-cell-role="th">symmetry_mean</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">texture_worst</th>
<th data-quarto-table-cell-role="th">perimeter_worst</th>
<th data-quarto-table-cell-role="th">area_worst</th>
<th data-quarto-table-cell-role="th">smoothness_worst</th>
<th data-quarto-table-cell-role="th">compactness_worst</th>
<th data-quarto-table-cell-role="th">concavity_worst</th>
<th data-quarto-table-cell-role="th">concave points_worst</th>
<th data-quarto-table-cell-role="th">symmetry_worst</th>
<th data-quarto-table-cell-role="th">fractal_dimension_worst</th>
<th data-quarto-table-cell-role="th">Unnamed: 32</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">count</th>
<td>5.690000e+02</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>...</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>0.0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">mean</th>
<td>3.037183e+07</td>
<td>14.127292</td>
<td>19.289649</td>
<td>91.969033</td>
<td>654.889104</td>
<td>0.096360</td>
<td>0.104341</td>
<td>0.088799</td>
<td>0.048919</td>
<td>0.181162</td>
<td>...</td>
<td>25.677223</td>
<td>107.261213</td>
<td>880.583128</td>
<td>0.132369</td>
<td>0.254265</td>
<td>0.272188</td>
<td>0.114606</td>
<td>0.290076</td>
<td>0.083946</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">std</th>
<td>1.250206e+08</td>
<td>3.524049</td>
<td>4.301036</td>
<td>24.298981</td>
<td>351.914129</td>
<td>0.014064</td>
<td>0.052813</td>
<td>0.079720</td>
<td>0.038803</td>
<td>0.027414</td>
<td>...</td>
<td>6.146258</td>
<td>33.602542</td>
<td>569.356993</td>
<td>0.022832</td>
<td>0.157336</td>
<td>0.208624</td>
<td>0.065732</td>
<td>0.061867</td>
<td>0.018061</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">min</th>
<td>8.670000e+03</td>
<td>6.981000</td>
<td>9.710000</td>
<td>43.790000</td>
<td>143.500000</td>
<td>0.052630</td>
<td>0.019380</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.106000</td>
<td>...</td>
<td>12.020000</td>
<td>50.410000</td>
<td>185.200000</td>
<td>0.071170</td>
<td>0.027290</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156500</td>
<td>0.055040</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">25%</th>
<td>8.692180e+05</td>
<td>11.700000</td>
<td>16.170000</td>
<td>75.170000</td>
<td>420.300000</td>
<td>0.086370</td>
<td>0.064920</td>
<td>0.029560</td>
<td>0.020310</td>
<td>0.161900</td>
<td>...</td>
<td>21.080000</td>
<td>84.110000</td>
<td>515.300000</td>
<td>0.116600</td>
<td>0.147200</td>
<td>0.114500</td>
<td>0.064930</td>
<td>0.250400</td>
<td>0.071460</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">50%</th>
<td>9.060240e+05</td>
<td>13.370000</td>
<td>18.840000</td>
<td>86.240000</td>
<td>551.100000</td>
<td>0.095870</td>
<td>0.092630</td>
<td>0.061540</td>
<td>0.033500</td>
<td>0.179200</td>
<td>...</td>
<td>25.410000</td>
<td>97.660000</td>
<td>686.500000</td>
<td>0.131300</td>
<td>0.211900</td>
<td>0.226700</td>
<td>0.099930</td>
<td>0.282200</td>
<td>0.080040</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">75%</th>
<td>8.813129e+06</td>
<td>15.780000</td>
<td>21.800000</td>
<td>104.100000</td>
<td>782.700000</td>
<td>0.105300</td>
<td>0.130400</td>
<td>0.130700</td>
<td>0.074000</td>
<td>0.195700</td>
<td>...</td>
<td>29.720000</td>
<td>125.400000</td>
<td>1084.000000</td>
<td>0.146000</td>
<td>0.339100</td>
<td>0.382900</td>
<td>0.161400</td>
<td>0.317900</td>
<td>0.092080</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">max</th>
<td>9.113205e+08</td>
<td>28.110000</td>
<td>39.280000</td>
<td>188.500000</td>
<td>2501.000000</td>
<td>0.163400</td>
<td>0.345400</td>
<td>0.426800</td>
<td>0.201200</td>
<td>0.304000</td>
<td>...</td>
<td>49.540000</td>
<td>251.200000</td>
<td>4254.000000</td>
<td>0.222600</td>
<td>1.058000</td>
<td>1.252000</td>
<td>0.291000</td>
<td>0.663800</td>
<td>0.207500</td>
<td>NaN</td>
</tr>
</tbody>
</table>

<p>8 rows × 32 columns</p>
</div>
</div>
</div>
</section>

<section id="diagnosis" class="title-slide slide level1 center">
<h1><code>diagnosis</code></h1>
<div id="cell-14" class="cell" data-execution_count="6">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb6-1"><a href=""></a>df[<span class="st">'diagnosis'</span>].value_counts()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>diagnosis
B    357
M    212
Name: count, dtype: int64</code></pre>
</div>
</div>
<div id="cell-15" class="cell" data-execution_count="7">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb8-1"><a href=""></a>sns.countplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'diagnosis'</span>, hue<span class="op">=</span><span class="st">'diagnosis'</span>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-8-output-1.png" class="r-stretch"></section>

<section id="summing-up" class="title-slide slide level1 center">
<h1>Summing up</h1>
<table class="caption-top">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Question</th>
<th>Answer</th>
<th>Do we need action?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Are there null values?</td>
<td>Yes</td>
<td>No need for imputation, drop the column</td>
</tr>
<tr class="even">
<td>Which are the attribute types?</td>
<td>All attributes are numeric but <code>diagnosis</code></td>
<td>Encode diagnosis</td>
</tr>
<tr class="odd">
<td>Which are the attribute ranges?</td>
<td>Attribute ranges are similar</td>
<td>We could apply normalization</td>
</tr>
<tr class="even">
<td>How many labels?</td>
<td>2</td>
<td>-</td>
</tr>
<tr class="odd">
<td>Are classes unbalanced?</td>
<td>No, classess are almost equally distributed</td>
<td>No rebalancing</td>
</tr>
</tbody>
</table>
</section>

<section id="data-preprocessing-drop-the-unnecessary-columns" class="title-slide slide level1 center">
<h1>Data preprocessing: Drop the unnecessary columns</h1>
<div id="cell-21" class="cell" data-execution_count="11">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb9-1"><a href=""></a><span class="co"># `Unnamed:32` has 0 non null objects, all values are null. Drop the column</span></span>
<span id="cb9-2"><a href=""></a>df.drop([<span class="st">"id"</span>, <span class="st">"Unnamed: 32"</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</details>
</div>
</section>

<section id="data-preprocessing-encoding" class="title-slide slide level1 center">
<h1>Data preprocessing: Encoding</h1>
<div id="cell-23" class="cell" data-execution_count="12">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb10-1"><a href=""></a><span class="co"># map the diagnosis column to numeric</span></span>
<span id="cb10-2"><a href=""></a>df[<span class="st">'diagnosis'</span>] <span class="op">=</span> df[<span class="st">'diagnosis'</span>].<span class="bu">map</span>({<span class="st">'M'</span>: <span class="dv">1</span>, <span class="st">'B'</span>: <span class="dv">0</span>})</span></code></pre></div>
</details>
</div>
</section>

<section id="data-visualization" class="title-slide slide level1 center">
<h1>Data visualization</h1>
<p>For now, let’s just focus on <code>*_mean</code> attributes</p>
<div id="cell-25" class="cell" data-execution_count="13">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb11-1"><a href=""></a>features_mean <span class="op">=</span> <span class="bu">list</span>(df.columns[<span class="dv">1</span>:<span class="dv">11</span>]) <span class="op">+</span> [<span class="st">"diagnosis"</span>]</span>
<span id="cb11-2"><a href=""></a>features_se <span class="op">=</span> <span class="bu">list</span>(df.columns[<span class="dv">11</span>:<span class="dv">20</span>]) <span class="op">+</span> [<span class="st">"diagnosis"</span>]</span>
<span id="cb11-3"><a href=""></a>features_worst <span class="op">=</span> <span class="bu">list</span>(df.columns[<span class="dv">21</span>:<span class="dv">31</span>]) <span class="op">+</span> [<span class="st">"diagnosis"</span>]</span>
<span id="cb11-4"><a href=""></a><span class="bu">print</span>(<span class="st">"features_mean: "</span> <span class="op">+</span> <span class="bu">str</span>(features_mean))</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>features_mean: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'diagnosis']</code></pre>
</div>
</div>
<div id="cell-26" class="cell" data-execution_count="14">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb13-1"><a href=""></a>df[features_mean].hist(bins<span class="op">=</span><span class="dv">50</span>, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">15</span>))</span>
<span id="cb13-2"><a href=""></a>plt.show()</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-15-output-1.png" class="r-stretch"></section>

<section id="checking-correlations" class="title-slide slide level1 center">
<h1>Checking correlations</h1>
<div id="cell-28" class="cell" data-execution_count="15">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb14-1"><a href=""></a>sns.pairplot(df[features_mean], hue<span class="op">=</span><span class="st">'diagnosis'</span>, markers<span class="op">=</span><span class="st">'+'</span>)</span>
<span id="cb14-2"><a href=""></a>plt.show()</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-16-output-1.png" class="r-stretch"></section>

<section id="section" class="title-slide slide level1 center">
<h1></h1>
<div id="cell-31" class="cell" data-execution_count="17">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb15-1"><a href=""></a>min_corr <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb15-2"><a href=""></a>kot <span class="op">=</span> rho[(<span class="bu">abs</span>(rho) <span class="op">&gt;=</span> min_corr) <span class="op">&amp;</span> (rho <span class="op">&lt;</span> <span class="dv">1</span>)]</span>
<span id="cb15-3"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">14</span>))</span>
<span id="cb15-4"><a href=""></a>sns.heatmap(kot, cmap<span class="op">=</span>sns.color_palette(<span class="st">"coolwarm"</span>, as_cmap<span class="op">=</span><span class="va">True</span>), annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span> <span class="st">'.2f'</span>,annot_kws<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">15</span>})</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-18-output-1.png" class="r-stretch"></section>

<section id="should-we-drop-some-attributes" class="title-slide slide level1 center">
<h1>Should we drop some attributes?</h1>
<ul>
<li><code>radius_mean</code>, <code>perimeter_mean</code>, and <code>area_mean</code> are highly correlated, keep <code>perimeter</code></li>
<li><code>compactness_mean</code>, <code>concavity_mean</code> and <code>concavepoint_mean</code> are highly correlated, keep <code>compactness_mean</code></li>
</ul>
<div id="cell-33" class="cell" data-execution_count="18">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb16-1"><a href=""></a><span class="co"># now these are the variables that we will use for prediction</span></span>
<span id="cb16-2"><a href=""></a>prediction_var <span class="op">=</span> [<span class="st">'texture_mean'</span>, <span class="st">'perimeter_mean'</span>, <span class="st">'smoothness_mean'</span>, <span class="st">'compactness_mean'</span>, <span class="st">'symmetry_mean'</span>]</span></code></pre></div>
</details>
</div>
</section>

<section id="modeling-with-scikit-learn" class="title-slide slide level1 center">
<h1>Modeling with scikit-learn</h1>
<p>Preparing the datasets for the ML pipeline.</p>
<ul>
<li>X: the dataset</li>
<li>y: the labels</li>
</ul>
<div id="cell-35" class="cell" data-execution_count="19">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb17-1"><a href=""></a><span class="kw">def</span> set_dataset(feature_list, normalize<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb17-2"><a href=""></a>    X <span class="op">=</span> df[feature_list <span class="op">+</span> [<span class="st">'diagnosis'</span>]].drop(<span class="st">'diagnosis'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-3"><a href=""></a>    y <span class="op">=</span> df[<span class="st">'diagnosis'</span>]</span>
<span id="cb17-4"><a href=""></a>    <span class="cf">if</span> normalize: X <span class="op">=</span> (X <span class="op">-</span> X.mean()) <span class="op">/</span> X.std()</span>
<span id="cb17-5"><a href=""></a>    <span class="bu">print</span>(<span class="ss">f"X.shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, y.shape: </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-6"><a href=""></a>    <span class="cf">return</span> X, y</span>
<span id="cb17-7"><a href=""></a></span>
<span id="cb17-8"><a href=""></a>X, y <span class="op">=</span> set_dataset(prediction_var, <span class="va">True</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X.shape: (569, 5), y.shape: (569,)</code></pre>
</div>
</div>
</section>

<section id="splitting-the-datasets-into-a-training-set-and-a-testing-set" class="title-slide slide level1 center">
<h1>Splitting the datasets into a training set and a testing set</h1>
<p>Advantages</p>
<ul>
<li>By splitting the dataset pseudo-randomly into a two separate sets, we can train using one set and test using another.</li>
<li>This ensures that we won’t use the same observations in both sets.</li>
</ul>
<p>Disadvantages</p>
<ul>
<li>The accuracy scores for the testing set can vary depending on what observations are in the set.</li>
<li>This disadvantage can be countered using k-fold cross-validation.</li>
</ul>
<p>Notes</p>
<ul>
<li>The accuracy score of the models depends on the observations in the testing set, which is determined by the seed of the pseudo-random number generator (random_state parameter).</li>
<li>As a model’s complexity increases, the training accuracy increases.</li>
<li>If a model is too complex or not complex enough, the testing accuracy is lower.
<ul>
<li>E.g., K-NN models, the value of k determines the level of complexity.</li>
</ul></li>
</ul>
<div id="cell-37" class="cell" data-execution_count="20">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb19-1"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-2"><a href=""></a><span class="bu">print</span>(<span class="ss">f"y_train.shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, y_train.shape: </span><span class="sc">{</span>y_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>y_train.shape: (569, 5), y_train.shape: (398,)</code></pre>
</div>
</div>
</section>

<section id="visualizing-the-data-how" class="title-slide slide level1 center">
<h1>Visualizing the data… how?</h1>

</section>

<section id="visualizing-the-data-in-3d" class="title-slide slide level1 center">
<h1>Visualizing the data in 3D</h1>
<div id="cell-40" class="cell" data-execution_count="21">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb21-1"><a href=""></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb21-2"><a href=""></a></span>
<span id="cb21-3"><a href=""></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb21-4"><a href=""></a>ax <span class="op">=</span> fig.add_subplot(projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb21-5"><a href=""></a></span>
<span id="cb21-6"><a href=""></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb21-7"><a href=""></a>result <span class="op">=</span> pca.fit_transform(X_train)</span>
<span id="cb21-8"><a href=""></a></span>
<span id="cb21-9"><a href=""></a>ax.scatter(</span>
<span id="cb21-10"><a href=""></a>    xs<span class="op">=</span>result[:,<span class="dv">0</span>],</span>
<span id="cb21-11"><a href=""></a>    ys<span class="op">=</span>result[:,<span class="dv">1</span>],</span>
<span id="cb21-12"><a href=""></a>    zs<span class="op">=</span>result[:,<span class="dv">2</span>],</span>
<span id="cb21-13"><a href=""></a>    c<span class="op">=</span>y_train,</span>
<span id="cb21-14"><a href=""></a>    cmap<span class="op">=</span><span class="st">'viridis'</span></span>
<span id="cb21-15"><a href=""></a>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-22-output-1.png" class="r-stretch"></section>

<section id="visualizing-the-data-in-2d" class="title-slide slide level1 center">
<h1>Visualizing the data in 2D</h1>
<div id="cell-42" class="cell" data-execution_count="22">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb22-1"><a href=""></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb22-2"><a href=""></a>result <span class="op">=</span> pca.fit_transform(X_train)</span>
<span id="cb22-3"><a href=""></a></span>
<span id="cb22-4"><a href=""></a>plt.scatter(</span>
<span id="cb22-5"><a href=""></a>    x<span class="op">=</span>result[:,<span class="dv">0</span>],</span>
<span id="cb22-6"><a href=""></a>    y<span class="op">=</span>result[:,<span class="dv">1</span>] ,</span>
<span id="cb22-7"><a href=""></a>    c<span class="op">=</span>y_train,</span>
<span id="cb22-8"><a href=""></a>    cmap<span class="op">=</span><span class="st">'viridis'</span></span>
<span id="cb22-9"><a href=""></a>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-23-output-1.png" class="r-stretch"></section>

<section id="visualizing-the-data-in-2d-with-tsne" class="title-slide slide level1 center">
<h1>Visualizing the data in 2D (with TSNE)</h1>
<div id="cell-44" class="cell" data-execution_count="23">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb23-1"><a href=""></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb23-2"><a href=""></a></span>
<span id="cb23-3"><a href=""></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb23-4"><a href=""></a>result <span class="op">=</span> tsne.fit_transform(X_train)</span>
<span id="cb23-5"><a href=""></a></span>
<span id="cb23-6"><a href=""></a>plt.scatter(</span>
<span id="cb23-7"><a href=""></a>    x<span class="op">=</span>result[:,<span class="dv">0</span>],</span>
<span id="cb23-8"><a href=""></a>    y<span class="op">=</span>result[:,<span class="dv">1</span>],</span>
<span id="cb23-9"><a href=""></a>    c<span class="op">=</span>y_train,</span>
<span id="cb23-10"><a href=""></a>    cmap<span class="op">=</span><span class="st">'viridis'</span></span>
<span id="cb23-11"><a href=""></a>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-24-output-1.png" class="r-stretch"></section>

<section id="outlier-detection" class="title-slide slide level1 center">
<h1>Outlier detection</h1>
<div id="cell-46" class="cell" data-execution_count="48">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb24-1"><a href=""></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> IsolationForest</span>
<span id="cb24-2"><a href=""></a></span>
<span id="cb24-3"><a href=""></a>clf <span class="op">=</span> IsolationForest(random_state<span class="op">=</span>seed)</span>
<span id="cb24-4"><a href=""></a>clf.fit(X_train)</span>
<span id="cb24-5"><a href=""></a>is_outlier <span class="op">=</span> clf.predict(X_train)</span>
<span id="cb24-6"><a href=""></a></span>
<span id="cb24-7"><a href=""></a>plt.scatter(</span>
<span id="cb24-8"><a href=""></a>    x<span class="op">=</span>result[:,<span class="dv">0</span>],</span>
<span id="cb24-9"><a href=""></a>    y<span class="op">=</span>result[:,<span class="dv">1</span>],</span>
<span id="cb24-10"><a href=""></a>    s<span class="op">=</span>[<span class="dv">10</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">40</span> <span class="cf">for</span> x <span class="kw">in</span> is_outlier],</span>
<span id="cb24-11"><a href=""></a>    c<span class="op">=</span>is_outlier,</span>
<span id="cb24-12"><a href=""></a>    cmap<span class="op">=</span><span class="st">'viridis'</span></span>
<span id="cb24-13"><a href=""></a>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-25-output-1.png" class="r-stretch"></section>

<section id="diagnosis-of-outliers" class="title-slide slide level1 center">
<h1><code>diagnosis</code> of outliers</h1>
<div id="cell-48" class="cell" data-execution_count="52">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb25-1"><a href=""></a>outlier_labels <span class="op">=</span> y_train[is_outlier <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb25-2"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="fl">2.5</span>))</span>
<span id="cb25-3"><a href=""></a>outlier_labels.hist()</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-26-output-1.png" class="r-stretch"><p>Outliers are mostly with a bad diagnosis, we do not drop them</p>
</section>

<section id="logistic-regression" class="title-slide slide level1 center">
<h1>Logistic regression</h1>
<div id="cell-51" class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb26-1"><a href=""></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb26-2"><a href=""></a></span>
<span id="cb26-3"><a href=""></a>logisticRegr <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>seed)  <span class="co"># all parameters not specified are set to their defaults</span></span>
<span id="cb26-4"><a href=""></a>logisticRegr.fit(X_train, y_train)</span>
<span id="cb26-5"><a href=""></a>y_pred <span class="op">=</span> logisticRegr.predict(X_test)</span>
<span id="cb26-6"><a href=""></a>metrics.accuracy_score(y_test, y_pred)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>0.9590643274853801</code></pre>
</div>
</div>
</section>

<section id="k-nearest-neighbors" class="title-slide slide level1 center">
<h1>k-Nearest Neighbors</h1>
<div id="cell-53" class="cell" data-execution_count="26">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb28-1"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb28-2"><a href=""></a><span class="kw">def</span> fit_knn(X_train, y_train, X_test, y_test):</span>
<span id="cb28-3"><a href=""></a>    k_range <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">30</span>))</span>
<span id="cb28-4"><a href=""></a>    scores <span class="op">=</span> []</span>
<span id="cb28-5"><a href=""></a>    conf_matrix <span class="op">=</span> <span class="va">None</span></span>
<span id="cb28-6"><a href=""></a>    <span class="cf">for</span> k <span class="kw">in</span> k_range:</span>
<span id="cb28-7"><a href=""></a>        knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k)</span>
<span id="cb28-8"><a href=""></a>        knn.fit(X_train, y_train)</span>
<span id="cb28-9"><a href=""></a>        y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb28-10"><a href=""></a>        scores.append(metrics.accuracy_score(y_test, y_pred))</span>
<span id="cb28-11"><a href=""></a>        <span class="cf">if</span> k <span class="op">==</span> <span class="dv">1</span>: conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb28-12"><a href=""></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="fl">2.5</span>))</span>
<span id="cb28-13"><a href=""></a>    <span class="cf">if</span> conf_matrix <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb28-14"><a href=""></a>        sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, cbar<span class="op">=</span><span class="va">False</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb28-15"><a href=""></a>        axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Predicted labels'</span>)</span>
<span id="cb28-16"><a href=""></a>        axes[<span class="dv">0</span>].set_ylabel(<span class="st">'True labels'</span>)</span>
<span id="cb28-17"><a href=""></a>        axes[<span class="dv">0</span>].set_title(<span class="st">'Confusion Matrix (k=1)'</span>)</span>
<span id="cb28-18"><a href=""></a>    axes[<span class="dv">1</span>].plot(k_range, scores, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb28-19"><a href=""></a>    axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Value of k for KNN'</span>)</span>
<span id="cb28-20"><a href=""></a>    axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Accuracy Score'</span>)</span>
<span id="cb28-21"><a href=""></a>    axes[<span class="dv">1</span>].grid(<span class="va">True</span>)</span>
<span id="cb28-22"><a href=""></a>    fig.tight_layout()</span>
<span id="cb28-23"><a href=""></a>    <span class="cf">return</span> y_pred</span>
<span id="cb28-24"><a href=""></a>p <span class="op">=</span> fit_knn(X_train, y_train, X_test, y_test)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-28-output-1.png" class="r-stretch"></section>

<section id="train-vs-train" class="title-slide slide level1 center">
<h1>Train vs train</h1>
<p>What if I compare the model vs the model trained on the training set only?</p>
<div id="cell-55" class="cell" data-execution_count="27">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb29-1"><a href=""></a>p <span class="op">=</span> fit_knn(X_train, y_train, X_train, y_train)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-29-output-1.png" class="r-stretch"></section>

<section id="what-if-i-choose-a-more-complex-model" class="title-slide slide level1 center">
<h1>What if I choose a more complex model?</h1>
<div id="cell-57" class="cell" data-execution_count="28">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb30-1"><a href=""></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb30-2"><a href=""></a></span>
<span id="cb30-3"><a href=""></a><span class="kw">def</span> fit_forest(X_train, y_train, X_test, y_test):</span>
<span id="cb30-4"><a href=""></a>    model<span class="op">=</span>RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed) <span class="co"># a simple random forest model</span></span>
<span id="cb30-5"><a href=""></a>    model.fit(X_train, y_train) <span class="co"># now fit our model for training data</span></span>
<span id="cb30-6"><a href=""></a>    y_pred <span class="op">=</span> model.predict(X_test) <span class="co"># predict for the test data</span></span>
<span id="cb30-7"><a href=""></a>    <span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>metrics<span class="sc">.</span>accuracy_score(y_pred, y_test)<span class="sc">}</span><span class="ss">"</span>) <span class="co"># to check the accuracy</span></span>
<span id="cb30-8"><a href=""></a>    featimp <span class="op">=</span> pd.Series(model.feature_importances_, index<span class="op">=</span>X_train.columns).sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb30-9"><a href=""></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Features sorted by descending importance:"</span>)</span>
<span id="cb30-10"><a href=""></a>    <span class="bu">print</span>(featimp) <span class="co"># this is the property of Random Forest classifier that it provide us the importance of the features used</span></span>
<span id="cb30-11"><a href=""></a></span>
<span id="cb30-12"><a href=""></a>fit_forest(X_train, y_train, X_test, y_test)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.9473684210526315

Features sorted by descending importance:
perimeter_mean      0.503717
compactness_mean    0.218286
texture_mean        0.138502
smoothness_mean     0.073035
symmetry_mean       0.066460
dtype: float64</code></pre>
</div>
</div>
</section>

<section id="section-1" class="title-slide slide level1 center">
<h1></h1>
<p>Now lets do this for all <code>feature_mean</code> so that from Random forest we can get the feature which are important</p>
<div id="cell-59" class="cell" data-execution_count="29">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb32-1"><a href=""></a>X, y <span class="op">=</span> set_dataset(features_mean, <span class="va">True</span>) <span class="co"># taking all features</span></span>
<span id="cb32-2"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb32-3"><a href=""></a>fit_forest(X_train, y_train, X_test, y_test)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X.shape: (569, 10), y.shape: (569,)
Accuracy: 0.935672514619883

Features sorted by descending importance:
concave points_mean       0.254215
area_mean                 0.183817
perimeter_mean            0.138935
radius_mean               0.132016
concavity_mean            0.123542
texture_mean              0.063192
compactness_mean          0.044789
smoothness_mean           0.025150
symmetry_mean             0.020292
fractal_dimension_mean    0.014051
dtype: float64</code></pre>
</div>
</div>
</section>

<section id="cross-validation" class="title-slide slide level1 center">
<h1><a href="https://scikit-learn.org/stable/modules/cross_validation.html">Cross-validation</a></h1>
<div id="cell-61" class="cell" data-execution_count="30">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb34-1"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb34-2"><a href=""></a></span>
<span id="cb34-3"><a href=""></a><span class="kw">def</span> cv(model, X, y):</span>
<span id="cb34-4"><a href=""></a>    scores <span class="op">=</span> cross_val_score(model, X, y, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb34-5"><a href=""></a>    <span class="bu">print</span>(<span class="st">"Scores: "</span> <span class="op">+</span> <span class="bu">str</span>(scores))</span>
<span id="cb34-6"><a href=""></a>    <span class="bu">print</span>(<span class="st">"</span><span class="sc">%0.3f</span><span class="st"> accuracy with a standard deviation of </span><span class="sc">%0.2f</span><span class="st">"</span> <span class="op">%</span> (scores.mean(), scores.std()))</span>
<span id="cb34-7"><a href=""></a></span>
<span id="cb34-8"><a href=""></a>cv(RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed), X, y)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Scores: [0.90350877 0.93859649 0.92105263 0.97368421 0.95575221]
0.939 accuracy with a standard deviation of 0.02</code></pre>
</div>
</div>
<div id="cell-62" class="cell" data-execution_count="31">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb36-1"><a href=""></a>cv(KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>), X, y)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Scores: [0.92105263 0.94736842 0.94736842 0.97368421 0.92035398]
0.942 accuracy with a standard deviation of 0.02</code></pre>
</div>
</div>
</section>

<section id="hyperparameter-optimization" class="title-slide slide level1 center">
<h1>Hyperparameter optimization</h1>
<div id="cell-64" class="cell" data-execution_count="32">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb38-1"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb38-2"><a href=""></a></span>
<span id="cb38-3"><a href=""></a><span class="kw">def</span> gridsearch_cv(model,param_grid, X_train, y_train):</span>
<span id="cb38-4"><a href=""></a>    clf <span class="op">=</span> GridSearchCV(model, param_grid, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">"accuracy"</span>, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb38-5"><a href=""></a>    clf.fit(X_train, y_train)</span>
<span id="cb38-6"><a href=""></a>    <span class="bu">print</span>(<span class="ss">f"The best score is </span><span class="sc">{</span>clf<span class="sc">.</span>best_score_<span class="sc">}</span><span class="ss">, with parameters </span><span class="sc">{</span>clf<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-7"><a href=""></a>    <span class="cf">return</span> clf.best_estimator_</span></code></pre></div>
</details>
</div>
<div id="cell-65" class="cell" data-execution_count="33">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb39-1"><a href=""></a>param_grid <span class="op">=</span> {</span>
<span id="cb39-2"><a href=""></a>    <span class="st">'n_neighbors'</span>: <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">30</span>, <span class="dv">3</span>)),</span>
<span id="cb39-3"><a href=""></a>    <span class="st">'leaf_size'</span>: <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">30</span>, <span class="dv">3</span>))</span>
<span id="cb39-4"><a href=""></a>}</span>
<span id="cb39-5"><a href=""></a>gridsearch_cv(KNeighborsClassifier(), param_grid, X, y)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 100 candidates, totalling 500 fits
The best score is 0.9455364073901567, with parameters {'leaf_size': 1, 'n_neighbors': 16}</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="33">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(leaf_size=1, n_neighbors=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;KNeighborsClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">?<span>Documentation for KNeighborsClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(leaf_size=1, n_neighbors=16)</pre></div> </div></div></div></div>
</div>
</div>
<div id="cell-66" class="cell" data-execution_count="34">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb41-1"><a href=""></a>param_grid <span class="op">=</span> {</span>
<span id="cb41-2"><a href=""></a>    <span class="st">'n_estimators'</span>: [<span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>],</span>
<span id="cb41-3"><a href=""></a>    <span class="st">"random_state"</span>: [seed]</span>
<span id="cb41-4"><a href=""></a>}</span>
<span id="cb41-5"><a href=""></a>clf <span class="op">=</span> gridsearch_cv(RandomForestClassifier(), param_grid, X, y)</span>
<span id="cb41-6"><a href=""></a>clf</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 3 candidates, totalling 15 fits
The best score is 0.9385188635305077, with parameters {'n_estimators': 50, 'random_state': 42}</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="34">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked=""><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RandomForestClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre></div> </div></div></div></div>
</div>
</div>
</section>

<section id="feature-selection" class="title-slide slide level1 center">
<h1>Feature selection</h1>
<div id="cell-68" class="cell" data-execution_count="35">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb43-1"><a href=""></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> RFECV</span>
<span id="cb43-2"><a href=""></a>rfecv <span class="op">=</span> RFECV(estimator<span class="op">=</span>clf, step<span class="op">=</span><span class="dv">1</span>, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">"accuracy"</span>, min_features_to_select<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=</span><span class="dv">2</span>, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb43-3"><a href=""></a>rfecv.fit(X, y)</span>
<span id="cb43-4"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Optimal number of features: </span><span class="sc">{</span>rfecv<span class="sc">.</span>n_features_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-5"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Feature ranking: </span><span class="sc">{</span>rfecv<span class="sc">.</span>ranking_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-6"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Selected features: </span><span class="sc">{</span><span class="bu">list</span>(X.columns[rfecv.support_])<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting estimator with 10 features.
Optimal number of features: 9
Feature ranking: [1 1 1 1 1 1 1 1 2 1]
Selected features: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'fractal_dimension_mean']</code></pre>
</div>
</div>
<div id="cell-69" class="cell" data-execution_count="36">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb45-1"><a href=""></a>cv_results <span class="op">=</span> pd.DataFrame(rfecv.cv_results_)</span>
<span id="cb45-2"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="fl">2.5</span>))</span>
<span id="cb45-3"><a href=""></a>plt.xlabel(<span class="st">"Number of features selected"</span>)</span>
<span id="cb45-4"><a href=""></a>plt.ylabel(<span class="st">"Mean test accuracy"</span>)</span>
<span id="cb45-5"><a href=""></a>plt.errorbar(x<span class="op">=</span>cv_results[<span class="st">"n_features"</span>], y<span class="op">=</span>cv_results[<span class="st">"mean_test_score"</span>], yerr<span class="op">=</span>cv_results[<span class="st">"std_test_score"</span>],)</span>
<span id="cb45-6"><a href=""></a>plt.title(<span class="st">"Recursive Feature Elimination"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>Text(0.5, 1.0, 'Recursive Feature Elimination')</code></pre>
</div>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-38-output-2.png" class="r-stretch"></section>

<section id="section-2" class="title-slide slide level1 center">
<h1></h1>
<div id="cell-71" class="cell" data-execution_count="37">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb47-1"><a href=""></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> RFE</span>
<span id="cb47-2"><a href=""></a></span>
<span id="cb47-3"><a href=""></a>rfe <span class="op">=</span> RFE(clf, n_features_to_select<span class="op">=</span><span class="dv">6</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-4"><a href=""></a>rfe <span class="op">=</span> rfe.fit(X, y)</span>
<span id="cb47-5"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Selected features:</span><span class="ch">\n</span><span class="sc">{</span><span class="bu">sorted</span>(X.columns[rfe.support_])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb47-6"><a href=""></a><span class="bu">print</span>(<span class="ss">f"... vs the features we have manually selected:</span><span class="ch">\n</span><span class="sc">{</span><span class="bu">sorted</span>(prediction_var)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Selected features:
['area_mean', 'concave points_mean', 'concavity_mean', 'perimeter_mean', 'radius_mean', 'texture_mean']
... vs the features we have manually selected:
['compactness_mean', 'perimeter_mean', 'smoothness_mean', 'symmetry_mean', 'texture_mean']</code></pre>
</div>
</div>
</section>

<section id="scikit-learn-pipelines" class="title-slide slide level1 center">
<h1>Scikit-learn pipelines</h1>
<div id="cell-73" class="cell" data-execution_count="38">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb49-1"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb49-2"><a href=""></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb49-3"><a href=""></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb49-4"><a href=""></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb49-5"><a href=""></a></span>
<span id="cb49-6"><a href=""></a>pipeline <span class="op">=</span> Pipeline([               <span class="co"># Create a pipeline with scaling and SVC</span></span>
<span id="cb49-7"><a href=""></a>    (<span class="st">'scaler'</span>, StandardScaler()),   <span class="co"># Step 1: Scale the features</span></span>
<span id="cb49-8"><a href=""></a>    (<span class="st">'svc'</span>, SVC())                  <span class="co"># Step 2: Apply Support Vector Classifier</span></span>
<span id="cb49-9"><a href=""></a>])</span>
<span id="cb49-10"><a href=""></a></span>
<span id="cb49-11"><a href=""></a>param_grid <span class="op">=</span> {                                  <span class="co"># Define the parameter grid to search</span></span>
<span id="cb49-12"><a href=""></a>    <span class="st">'scaler__with_mean'</span>: [<span class="va">True</span>, <span class="va">False</span>],         <span class="co"># Different values of with_mean for StandardScaler</span></span>
<span id="cb49-13"><a href=""></a>    <span class="st">'svc__C'</span>: [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>],                     <span class="co"># Different values of C for SVC</span></span>
<span id="cb49-14"><a href=""></a>    <span class="st">'svc__kernel'</span>: [<span class="st">'linear'</span>, <span class="st">'rbf'</span>, <span class="st">'poly'</span>],   <span class="co"># Different kernel functions for SVC</span></span>
<span id="cb49-15"><a href=""></a>    <span class="st">'svc__random_state'</span>: [seed]</span>
<span id="cb49-16"><a href=""></a>}</span>
<span id="cb49-17"><a href=""></a></span>
<span id="cb49-18"><a href=""></a>grid_search <span class="op">=</span> GridSearchCV(pipeline, param_grid, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb49-19"><a href=""></a>grid_search.fit(X_train, y_train)</span>
<span id="cb49-20"><a href=""></a>best_estimator <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb49-21"><a href=""></a>y_pred <span class="op">=</span> grid_search.predict(X_test)</span>
<span id="cb49-22"><a href=""></a><span class="bu">print</span>(<span class="ss">f"The best score is </span><span class="sc">{</span>grid_search<span class="sc">.</span>best_score_<span class="sc">}</span><span class="ss">, with parameters </span><span class="sc">{</span>grid_search<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-23"><a href=""></a>grid_search.best_estimator_</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best score is 0.9371202531645568, with parameters {'svc__C': 10, 'svc__kernel': 'rbf', 'svc__random_state': 42}</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="38">
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('scaler', StandardScaler()),
                ('svc', SVC(C=10, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('scaler', StandardScaler()),
                ('svc', SVC(C=10, random_state=42))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox"><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;StandardScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SVC<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html">?<span>Documentation for SVC</span></a></label><div class="sk-toggleable__content fitted"><pre>SVC(C=10, random_state=42)</pre></div> </div></div></div></div></div></div>
</div>
</div>
</section>

<section id="automl" class="title-slide slide level1 center">
<h1>AutoML</h1>
<div id="cell-75" class="cell" data-execution_count="39">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb51-1"><a href=""></a><span class="kw">def</span> auto_ml(max_iter<span class="op">=</span><span class="dv">300</span>):</span>
<span id="cb51-2"><a href=""></a>    automl <span class="op">=</span> AutoML()</span>
<span id="cb51-3"><a href=""></a>    settings <span class="op">=</span> {</span>
<span id="cb51-4"><a href=""></a>        <span class="st">"time_budget"</span>: <span class="op">-</span><span class="dv">1</span>,  <span class="co"># in seconds (-1 = unlimited)</span></span>
<span id="cb51-5"><a href=""></a>        <span class="st">"max_iter"</span>: max_iter,  <span class="co"># maximum iterations of the search</span></span>
<span id="cb51-6"><a href=""></a>        <span class="st">"metric"</span>: <span class="st">'accuracy'</span>,</span>
<span id="cb51-7"><a href=""></a>        <span class="st">"task"</span>: <span class="st">'classification'</span>,</span>
<span id="cb51-8"><a href=""></a>        <span class="st">"seed"</span>: seed</span>
<span id="cb51-9"><a href=""></a>    }</span>
<span id="cb51-10"><a href=""></a>    automl.fit(X_train<span class="op">=</span>X_train, y_train<span class="op">=</span>y_train, <span class="op">**</span>settings)  <span class="co"># Search for the best model and hyperparameters</span></span>
<span id="cb51-11"><a href=""></a>    y_pred <span class="op">=</span> automl.predict(X_test)  <span class="co"># Make predictions on the test set</span></span>
<span id="cb51-12"><a href=""></a>    <span class="cf">return</span> automl, y_pred</span>
<span id="cb51-13"><a href=""></a></span>
<span id="cb51-14"><a href=""></a>automl, y_pred <span class="op">=</span> auto_ml(<span class="dv">300</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[flaml.automl.logger: 12-03 15:11:52] {1728} INFO - task = classification
[flaml.automl.logger: 12-03 15:11:52] {1739} INFO - Evaluation method: cv
[flaml.automl.logger: 12-03 15:11:52] {1838} INFO - Minimizing error metric: 1-accuracy
[flaml.automl.logger: 12-03 15:11:52] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'lrl1']
[flaml.automl.logger: 12-03 15:11:52] {2258} INFO - iteration 0, current learner lgbm
[flaml.automl.logger: 12-03 15:11:52] {2393} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.
[flaml.automl.logger: 12-03 15:11:52] {2442} INFO -  at 0.3s,   estimator lgbm's best error=0.1181, best estimator lgbm's best error=0.1181
[flaml.automl.logger: 12-03 15:11:52] {2258} INFO - iteration 1, current learner lgbm
[flaml.automl.logger: 12-03 15:11:53] {2442} INFO -  at 0.5s,   estimator lgbm's best error=0.1181, best estimator lgbm's best error=0.1181
[flaml.automl.logger: 12-03 15:11:53] {2258} INFO - iteration 2, current learner lgbm
[flaml.automl.logger: 12-03 15:11:53] {2442} INFO -  at 0.7s,   estimator lgbm's best error=0.0955, best estimator lgbm's best error=0.0955
[flaml.automl.logger: 12-03 15:11:53] {2258} INFO - iteration 3, current learner rf
[flaml.automl.logger: 12-03 15:11:53] {2442} INFO -  at 1.0s,   estimator rf's best error=0.0781,   best estimator rf's best error=0.0781
[flaml.automl.logger: 12-03 15:11:53] {2258} INFO - iteration 4, current learner lgbm
[flaml.automl.logger: 12-03 15:11:54] {2442} INFO -  at 1.6s,   estimator lgbm's best error=0.0831, best estimator rf's best error=0.0781
[flaml.automl.logger: 12-03 15:11:54] {2258} INFO - iteration 5, current learner lgbm
[flaml.automl.logger: 12-03 15:11:54] {2442} INFO -  at 1.8s,   estimator lgbm's best error=0.0831, best estimator rf's best error=0.0781
[flaml.automl.logger: 12-03 15:11:54] {2258} INFO - iteration 6, current learner lgbm
[flaml.automl.logger: 12-03 15:11:55] {2442} INFO -  at 2.4s,   estimator lgbm's best error=0.0730, best estimator lgbm's best error=0.0730
[flaml.automl.logger: 12-03 15:11:55] {2258} INFO - iteration 7, current learner lgbm
[flaml.automl.logger: 12-03 15:11:55] {2442} INFO -  at 3.0s,   estimator lgbm's best error=0.0655, best estimator lgbm's best error=0.0655
[flaml.automl.logger: 12-03 15:11:55] {2258} INFO - iteration 8, current learner lgbm
[flaml.automl.logger: 12-03 15:11:56] {2442} INFO -  at 3.5s,   estimator lgbm's best error=0.0655, best estimator lgbm's best error=0.0655
[flaml.automl.logger: 12-03 15:11:56] {2258} INFO - iteration 9, current learner lgbm
[flaml.automl.logger: 12-03 15:11:56] {2442} INFO -  at 4.1s,   estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:56] {2258} INFO - iteration 10, current learner rf
[flaml.automl.logger: 12-03 15:11:57] {2442} INFO -  at 4.7s,   estimator rf's best error=0.0781,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:57] {2258} INFO - iteration 11, current learner xgboost
[flaml.automl.logger: 12-03 15:11:57] {2442} INFO -  at 5.0s,   estimator xgboost's best error=0.1006,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:57] {2258} INFO - iteration 12, current learner rf
[flaml.automl.logger: 12-03 15:11:58] {2442} INFO -  at 5.4s,   estimator rf's best error=0.0756,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:58] {2258} INFO - iteration 13, current learner xgboost
[flaml.automl.logger: 12-03 15:11:58] {2442} INFO -  at 5.8s,   estimator xgboost's best error=0.1006,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:58] {2258} INFO - iteration 14, current learner extra_tree
[flaml.automl.logger: 12-03 15:11:58] {2442} INFO -  at 6.1s,   estimator extra_tree's best error=0.1108,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:58] {2258} INFO - iteration 15, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:11:59] {2442} INFO -  at 6.5s,   estimator xgb_limitdepth's best error=0.0655,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:59] {2258} INFO - iteration 16, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:11:59] {2442} INFO -  at 7.1s,   estimator xgb_limitdepth's best error=0.0630,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:59] {2258} INFO - iteration 17, current learner sgd
[flaml.automl.logger: 12-03 15:11:59] {2442} INFO -  at 7.3s,   estimator sgd's best error=0.0680,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:11:59] {2258} INFO - iteration 18, current learner xgboost
[flaml.automl.logger: 12-03 15:12:00] {2442} INFO -  at 7.7s,   estimator xgboost's best error=0.0705,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:00] {2258} INFO - iteration 19, current learner sgd
[flaml.automl.logger: 12-03 15:12:00] {2442} INFO -  at 7.8s,   estimator sgd's best error=0.0680,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:00] {2258} INFO - iteration 20, current learner lgbm
[flaml.automl.logger: 12-03 15:12:01] {2442} INFO -  at 8.5s,   estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:01] {2258} INFO - iteration 21, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:12:01] {2442} INFO -  at 8.9s,   estimator xgb_limitdepth's best error=0.0630,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:01] {2258} INFO - iteration 22, current learner extra_tree
[flaml.automl.logger: 12-03 15:12:01] {2442} INFO -  at 9.3s,   estimator extra_tree's best error=0.1107,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:01] {2258} INFO - iteration 23, current learner sgd
[flaml.automl.logger: 12-03 15:12:01] {2442} INFO -  at 9.4s,   estimator sgd's best error=0.0655,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:01] {2258} INFO - iteration 24, current learner lrl1
[flaml.automl.logger: 12-03 15:12:02] {2442} INFO -  at 9.5s,   estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:02] {2258} INFO - iteration 25, current learner lgbm
[flaml.automl.logger: 12-03 15:12:02] {2442} INFO -  at 10.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:02] {2258} INFO - iteration 26, current learner lgbm
[flaml.automl.logger: 12-03 15:12:03] {2442} INFO -  at 10.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:03] {2258} INFO - iteration 27, current learner lrl1
[flaml.automl.logger: 12-03 15:12:03] {2442} INFO -  at 10.9s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:03] {2258} INFO - iteration 28, current learner lrl1
[flaml.automl.logger: 12-03 15:12:03] {2442} INFO -  at 11.0s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:03] {2258} INFO - iteration 29, current learner xgboost
[flaml.automl.logger: 12-03 15:12:03] {2442} INFO -  at 11.3s,  estimator xgboost's best error=0.0705,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:03] {2258} INFO - iteration 30, current learner lrl1
[flaml.automl.logger: 12-03 15:12:04] {2442} INFO -  at 11.4s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:04] {2258} INFO - iteration 31, current learner lrl1
[flaml.automl.logger: 12-03 15:12:04] {2442} INFO -  at 11.6s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:04] {2258} INFO - iteration 32, current learner lrl1
[flaml.automl.logger: 12-03 15:12:04] {2442} INFO -  at 11.7s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:04] {2258} INFO - iteration 33, current learner lgbm
[flaml.automl.logger: 12-03 15:12:04] {2442} INFO -  at 12.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:04] {2258} INFO - iteration 34, current learner lgbm
[flaml.automl.logger: 12-03 15:12:05] {2442} INFO -  at 12.9s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:05] {2258} INFO - iteration 35, current learner lgbm
[flaml.automl.logger: 12-03 15:12:06] {2442} INFO -  at 13.9s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:06] {2258} INFO - iteration 36, current learner lrl1
[flaml.automl.logger: 12-03 15:12:06] {2442} INFO -  at 14.1s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:06] {2258} INFO - iteration 37, current learner lgbm
[flaml.automl.logger: 12-03 15:12:07] {2442} INFO -  at 14.5s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:07] {2258} INFO - iteration 38, current learner xgboost
[flaml.automl.logger: 12-03 15:12:07] {2442} INFO -  at 14.8s,  estimator xgboost's best error=0.0656,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:07] {2258} INFO - iteration 39, current learner lrl1
[flaml.automl.logger: 12-03 15:12:07] {2442} INFO -  at 15.0s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:07] {2258} INFO - iteration 40, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:12:08] {2442} INFO -  at 15.4s,  estimator xgb_limitdepth's best error=0.0630,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:08] {2258} INFO - iteration 41, current learner sgd
[flaml.automl.logger: 12-03 15:12:08] {2442} INFO -  at 15.7s,  estimator sgd's best error=0.0655,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:08] {2258} INFO - iteration 42, current learner rf
[flaml.automl.logger: 12-03 15:12:09] {2442} INFO -  at 16.4s,  estimator rf's best error=0.0731,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:09] {2258} INFO - iteration 43, current learner sgd
[flaml.automl.logger: 12-03 15:12:09] {2442} INFO -  at 16.5s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:09] {2258} INFO - iteration 44, current learner sgd
[flaml.automl.logger: 12-03 15:12:09] {2442} INFO -  at 16.8s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:09] {2258} INFO - iteration 45, current learner lgbm
[flaml.automl.logger: 12-03 15:12:09] {2442} INFO -  at 17.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:09] {2258} INFO - iteration 46, current learner sgd
[flaml.automl.logger: 12-03 15:12:09] {2442} INFO -  at 17.1s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:09] {2258} INFO - iteration 47, current learner lrl1
[flaml.automl.logger: 12-03 15:12:09] {2442} INFO -  at 17.3s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:09] {2258} INFO - iteration 48, current learner sgd
[flaml.automl.logger: 12-03 15:12:09] {2442} INFO -  at 17.3s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:09] {2258} INFO - iteration 49, current learner xgboost
[flaml.automl.logger: 12-03 15:12:10] {2442} INFO -  at 17.6s,  estimator xgboost's best error=0.0656,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:10] {2258} INFO - iteration 50, current learner sgd
[flaml.automl.logger: 12-03 15:12:10] {2442} INFO -  at 17.7s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:10] {2258} INFO - iteration 51, current learner lgbm
[flaml.automl.logger: 12-03 15:12:11] {2442} INFO -  at 19.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:11] {2258} INFO - iteration 52, current learner sgd
[flaml.automl.logger: 12-03 15:12:12] {2442} INFO -  at 19.5s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:12] {2258} INFO - iteration 53, current learner lrl1
[flaml.automl.logger: 12-03 15:12:12] {2442} INFO -  at 19.6s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:12] {2258} INFO - iteration 54, current learner xgboost
[flaml.automl.logger: 12-03 15:12:12] {2442} INFO -  at 20.0s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:12] {2258} INFO - iteration 55, current learner rf
[flaml.automl.logger: 12-03 15:12:13] {2442} INFO -  at 20.5s,  estimator rf's best error=0.0731,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:13] {2258} INFO - iteration 56, current learner lgbm
[flaml.automl.logger: 12-03 15:12:14] {2442} INFO -  at 21.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:14] {2258} INFO - iteration 57, current learner lgbm
[flaml.automl.logger: 12-03 15:12:14] {2442} INFO -  at 22.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:14] {2258} INFO - iteration 58, current learner sgd
[flaml.automl.logger: 12-03 15:12:14] {2442} INFO -  at 22.2s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:14] {2258} INFO - iteration 59, current learner rf
[flaml.automl.logger: 12-03 15:12:15] {2442} INFO -  at 22.9s,  estimator rf's best error=0.0731,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:15] {2258} INFO - iteration 60, current learner xgboost
[flaml.automl.logger: 12-03 15:12:15] {2442} INFO -  at 23.3s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:15] {2258} INFO - iteration 61, current learner sgd
[flaml.automl.logger: 12-03 15:12:16] {2442} INFO -  at 23.4s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:16] {2258} INFO - iteration 62, current learner lgbm
[flaml.automl.logger: 12-03 15:12:16] {2442} INFO -  at 24.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:16] {2258} INFO - iteration 63, current learner sgd
[flaml.automl.logger: 12-03 15:12:16] {2442} INFO -  at 24.3s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:16] {2258} INFO - iteration 64, current learner lgbm
[flaml.automl.logger: 12-03 15:12:17] {2442} INFO -  at 24.9s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:17] {2258} INFO - iteration 65, current learner sgd
[flaml.automl.logger: 12-03 15:12:17] {2442} INFO -  at 25.1s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:17] {2258} INFO - iteration 66, current learner sgd
[flaml.automl.logger: 12-03 15:12:17] {2442} INFO -  at 25.2s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:17] {2258} INFO - iteration 67, current learner lgbm
[flaml.automl.logger: 12-03 15:12:18] {2442} INFO -  at 25.5s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:18] {2258} INFO - iteration 68, current learner xgboost
[flaml.automl.logger: 12-03 15:12:18] {2442} INFO -  at 25.8s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:18] {2258} INFO - iteration 69, current learner lrl1
[flaml.automl.logger: 12-03 15:12:18] {2442} INFO -  at 25.9s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:18] {2258} INFO - iteration 70, current learner xgboost
[flaml.automl.logger: 12-03 15:12:18] {2442} INFO -  at 26.2s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:18] {2258} INFO - iteration 71, current learner lgbm
[flaml.automl.logger: 12-03 15:12:20] {2442} INFO -  at 27.5s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:20] {2258} INFO - iteration 72, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:12:20] {2442} INFO -  at 28.2s,  estimator xgb_limitdepth's best error=0.0629,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:20] {2258} INFO - iteration 73, current learner lrl1
[flaml.automl.logger: 12-03 15:12:21] {2442} INFO -  at 28.4s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:21] {2258} INFO - iteration 74, current learner xgboost
[flaml.automl.logger: 12-03 15:12:21] {2442} INFO -  at 29.2s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:21] {2258} INFO - iteration 75, current learner lrl1
[flaml.automl.logger: 12-03 15:12:22] {2442} INFO -  at 29.4s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:22] {2258} INFO - iteration 76, current learner lrl1
[flaml.automl.logger: 12-03 15:12:22] {2442} INFO -  at 29.5s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:22] {2258} INFO - iteration 77, current learner lrl1
[flaml.automl.logger: 12-03 15:12:22] {2442} INFO -  at 29.7s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:22] {2258} INFO - iteration 78, current learner lgbm
[flaml.automl.logger: 12-03 15:12:23] {2442} INFO -  at 30.5s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:23] {2258} INFO - iteration 79, current learner lgbm
[flaml.automl.logger: 12-03 15:12:23] {2442} INFO -  at 31.2s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:23] {2258} INFO - iteration 80, current learner lrl1
[flaml.automl.logger: 12-03 15:12:24] {2442} INFO -  at 31.4s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:24] {2258} INFO - iteration 81, current learner rf
[flaml.automl.logger: 12-03 15:12:24] {2442} INFO -  at 31.8s,  estimator rf's best error=0.0730,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:24] {2258} INFO - iteration 82, current learner lgbm
[flaml.automl.logger: 12-03 15:12:25] {2442} INFO -  at 32.5s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:25] {2258} INFO - iteration 83, current learner lrl1
[flaml.automl.logger: 12-03 15:12:25] {2442} INFO -  at 32.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:25] {2258} INFO - iteration 84, current learner lgbm
[flaml.automl.logger: 12-03 15:12:26] {2442} INFO -  at 33.5s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:26] {2258} INFO - iteration 85, current learner lrl1
[flaml.automl.logger: 12-03 15:12:26] {2442} INFO -  at 33.6s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:26] {2258} INFO - iteration 86, current learner lrl1
[flaml.automl.logger: 12-03 15:12:26] {2442} INFO -  at 33.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:26] {2258} INFO - iteration 87, current learner lrl1
[flaml.automl.logger: 12-03 15:12:26] {2442} INFO -  at 34.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:26] {2258} INFO - iteration 88, current learner lrl1
[flaml.automl.logger: 12-03 15:12:26] {2442} INFO -  at 34.1s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:26] {2258} INFO - iteration 89, current learner lrl1
[flaml.automl.logger: 12-03 15:12:26] {2442} INFO -  at 34.3s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:26] {2258} INFO - iteration 90, current learner lgbm
[flaml.automl.logger: 12-03 15:12:27] {2442} INFO -  at 34.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:27] {2258} INFO - iteration 91, current learner lgbm
[flaml.automl.logger: 12-03 15:12:27] {2442} INFO -  at 35.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:27] {2258} INFO - iteration 92, current learner lrl1
[flaml.automl.logger: 12-03 15:12:28] {2442} INFO -  at 35.5s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:28] {2258} INFO - iteration 93, current learner xgboost
[flaml.automl.logger: 12-03 15:12:28] {2442} INFO -  at 35.9s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:28] {2258} INFO - iteration 94, current learner lrl1
[flaml.automl.logger: 12-03 15:12:28] {2442} INFO -  at 36.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:28] {2258} INFO - iteration 95, current learner lrl1
[flaml.automl.logger: 12-03 15:12:28] {2442} INFO -  at 36.2s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:28] {2258} INFO - iteration 96, current learner lrl1
[flaml.automl.logger: 12-03 15:12:28] {2442} INFO -  at 36.3s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:28] {2258} INFO - iteration 97, current learner lgbm
[flaml.automl.logger: 12-03 15:12:29] {2442} INFO -  at 36.8s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:29] {2258} INFO - iteration 98, current learner lrl1
[flaml.automl.logger: 12-03 15:12:29] {2442} INFO -  at 37.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:29] {2258} INFO - iteration 99, current learner xgboost
[flaml.automl.logger: 12-03 15:12:30] {2442} INFO -  at 37.5s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:30] {2258} INFO - iteration 100, current learner lrl1
[flaml.automl.logger: 12-03 15:12:30] {2442} INFO -  at 37.6s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:30] {2258} INFO - iteration 101, current learner lgbm
[flaml.automl.logger: 12-03 15:12:30] {2442} INFO -  at 38.2s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:30] {2258} INFO - iteration 102, current learner lgbm
[flaml.automl.logger: 12-03 15:12:32] {2442} INFO -  at 39.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:32] {2258} INFO - iteration 103, current learner lrl1
[flaml.automl.logger: 12-03 15:12:32] {2442} INFO -  at 39.6s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:32] {2258} INFO - iteration 104, current learner lrl1
[flaml.automl.logger: 12-03 15:12:32] {2442} INFO -  at 39.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:32] {2258} INFO - iteration 105, current learner lgbm
[flaml.automl.logger: 12-03 15:12:32] {2442} INFO -  at 40.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:32] {2258} INFO - iteration 106, current learner lrl1
[flaml.automl.logger: 12-03 15:12:32] {2442} INFO -  at 40.1s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:32] {2258} INFO - iteration 107, current learner lgbm
[flaml.automl.logger: 12-03 15:12:33] {2442} INFO -  at 40.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:33] {2258} INFO - iteration 108, current learner lrl1
[flaml.automl.logger: 12-03 15:12:33] {2442} INFO -  at 40.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:33] {2258} INFO - iteration 109, current learner lrl1
[flaml.automl.logger: 12-03 15:12:33] {2442} INFO -  at 40.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:33] {2258} INFO - iteration 110, current learner lgbm
[flaml.automl.logger: 12-03 15:12:34] {2442} INFO -  at 41.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:34] {2258} INFO - iteration 111, current learner lrl1
[flaml.automl.logger: 12-03 15:12:34] {2442} INFO -  at 41.6s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:34] {2258} INFO - iteration 112, current learner lrl1
[flaml.automl.logger: 12-03 15:12:34] {2442} INFO -  at 41.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:34] {2258} INFO - iteration 113, current learner lgbm
[flaml.automl.logger: 12-03 15:12:35] {2442} INFO -  at 42.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:35] {2258} INFO - iteration 114, current learner lrl1
[flaml.automl.logger: 12-03 15:12:35] {2442} INFO -  at 42.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:35] {2258} INFO - iteration 115, current learner lrl1
[flaml.automl.logger: 12-03 15:12:35] {2442} INFO -  at 42.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:35] {2258} INFO - iteration 116, current learner lrl1
[flaml.automl.logger: 12-03 15:12:35] {2442} INFO -  at 43.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:35] {2258} INFO - iteration 117, current learner lgbm
[flaml.automl.logger: 12-03 15:12:36] {2442} INFO -  at 43.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:36] {2258} INFO - iteration 118, current learner lgbm
[flaml.automl.logger: 12-03 15:12:36] {2442} INFO -  at 43.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:36] {2258} INFO - iteration 119, current learner lrl1
[flaml.automl.logger: 12-03 15:12:36] {2442} INFO -  at 43.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:36] {2258} INFO - iteration 120, current learner lrl1
[flaml.automl.logger: 12-03 15:12:36] {2442} INFO -  at 44.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:36] {2258} INFO - iteration 121, current learner lgbm
[flaml.automl.logger: 12-03 15:12:37] {2442} INFO -  at 44.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:37] {2258} INFO - iteration 122, current learner lrl1
[flaml.automl.logger: 12-03 15:12:37] {2442} INFO -  at 44.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:37] {2258} INFO - iteration 123, current learner lrl1
[flaml.automl.logger: 12-03 15:12:37] {2442} INFO -  at 45.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:37] {2258} INFO - iteration 124, current learner lrl1
[flaml.automl.logger: 12-03 15:12:37] {2442} INFO -  at 45.1s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:37] {2258} INFO - iteration 125, current learner lrl1
[flaml.automl.logger: 12-03 15:12:37] {2442} INFO -  at 45.3s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:37] {2258} INFO - iteration 126, current learner lgbm
[flaml.automl.logger: 12-03 15:12:38] {2442} INFO -  at 46.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:38] {2258} INFO - iteration 127, current learner lgbm
[flaml.automl.logger: 12-03 15:12:38] {2442} INFO -  at 46.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:38] {2258} INFO - iteration 128, current learner lgbm
[flaml.automl.logger: 12-03 15:12:40] {2442} INFO -  at 47.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:40] {2258} INFO - iteration 129, current learner lgbm
[flaml.automl.logger: 12-03 15:12:40] {2442} INFO -  at 47.9s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:40] {2258} INFO - iteration 130, current learner lgbm
[flaml.automl.logger: 12-03 15:12:41] {2442} INFO -  at 48.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:41] {2258} INFO - iteration 131, current learner lrl1
[flaml.automl.logger: 12-03 15:12:41] {2442} INFO -  at 48.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:41] {2258} INFO - iteration 132, current learner lrl1
[flaml.automl.logger: 12-03 15:12:41] {2442} INFO -  at 48.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:41] {2258} INFO - iteration 133, current learner lrl1
[flaml.automl.logger: 12-03 15:12:41] {2442} INFO -  at 49.1s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:41] {2258} INFO - iteration 134, current learner lrl1
[flaml.automl.logger: 12-03 15:12:41] {2442} INFO -  at 49.2s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:41] {2258} INFO - iteration 135, current learner lgbm
[flaml.automl.logger: 12-03 15:12:42] {2442} INFO -  at 49.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:42] {2258} INFO - iteration 136, current learner lgbm
[flaml.automl.logger: 12-03 15:12:43] {2442} INFO -  at 50.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:43] {2258} INFO - iteration 137, current learner lrl1
[flaml.automl.logger: 12-03 15:12:43] {2442} INFO -  at 50.6s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:43] {2258} INFO - iteration 138, current learner lrl1
[flaml.automl.logger: 12-03 15:12:43] {2442} INFO -  at 50.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:43] {2258} INFO - iteration 139, current learner lrl1
[flaml.automl.logger: 12-03 15:12:43] {2442} INFO -  at 50.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:43] {2258} INFO - iteration 140, current learner lgbm
[flaml.automl.logger: 12-03 15:12:43] {2442} INFO -  at 51.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:43] {2258} INFO - iteration 141, current learner lrl1
[flaml.automl.logger: 12-03 15:12:44] {2442} INFO -  at 51.5s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:44] {2258} INFO - iteration 142, current learner lgbm
[flaml.automl.logger: 12-03 15:12:45] {2442} INFO -  at 52.9s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:45] {2258} INFO - iteration 143, current learner lrl1
[flaml.automl.logger: 12-03 15:12:45] {2442} INFO -  at 53.1s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:45] {2258} INFO - iteration 144, current learner lgbm
[flaml.automl.logger: 12-03 15:12:46] {2442} INFO -  at 53.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:46] {2258} INFO - iteration 145, current learner lrl1
[flaml.automl.logger: 12-03 15:12:46] {2442} INFO -  at 53.5s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:46] {2258} INFO - iteration 146, current learner lrl1
[flaml.automl.logger: 12-03 15:12:46] {2442} INFO -  at 53.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:46] {2258} INFO - iteration 147, current learner lrl1
[flaml.automl.logger: 12-03 15:12:46] {2442} INFO -  at 53.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:46] {2258} INFO - iteration 148, current learner lgbm
[flaml.automl.logger: 12-03 15:12:47] {2442} INFO -  at 55.1s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:47] {2258} INFO - iteration 149, current learner lgbm
[flaml.automl.logger: 12-03 15:12:48] {2442} INFO -  at 55.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:48] {2258} INFO - iteration 150, current learner lgbm
[flaml.automl.logger: 12-03 15:12:48] {2442} INFO -  at 55.9s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:48] {2258} INFO - iteration 151, current learner lgbm
[flaml.automl.logger: 12-03 15:12:49] {2442} INFO -  at 56.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:49] {2258} INFO - iteration 152, current learner lgbm
[flaml.automl.logger: 12-03 15:12:49] {2442} INFO -  at 56.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:49] {2258} INFO - iteration 153, current learner lgbm
[flaml.automl.logger: 12-03 15:12:50] {2442} INFO -  at 57.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:50] {2258} INFO - iteration 154, current learner lrl1
[flaml.automl.logger: 12-03 15:12:50] {2442} INFO -  at 57.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:50] {2258} INFO - iteration 155, current learner lrl1
[flaml.automl.logger: 12-03 15:12:50] {2442} INFO -  at 58.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:50] {2258} INFO - iteration 156, current learner lgbm
[flaml.automl.logger: 12-03 15:12:50] {2442} INFO -  at 58.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:50] {2258} INFO - iteration 157, current learner lgbm
[flaml.automl.logger: 12-03 15:12:51] {2442} INFO -  at 59.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:51] {2258} INFO - iteration 158, current learner lrl1
[flaml.automl.logger: 12-03 15:12:52] {2442} INFO -  at 59.5s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:52] {2258} INFO - iteration 159, current learner lrl1
[flaml.automl.logger: 12-03 15:12:52] {2442} INFO -  at 59.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:52] {2258} INFO - iteration 160, current learner lgbm
[flaml.automl.logger: 12-03 15:12:53] {2442} INFO -  at 60.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:53] {2258} INFO - iteration 161, current learner lgbm
[flaml.automl.logger: 12-03 15:12:53] {2442} INFO -  at 60.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:53] {2258} INFO - iteration 162, current learner lrl1
[flaml.automl.logger: 12-03 15:12:53] {2442} INFO -  at 60.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:53] {2258} INFO - iteration 163, current learner lgbm
[flaml.automl.logger: 12-03 15:12:54] {2442} INFO -  at 61.5s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:54] {2258} INFO - iteration 164, current learner lrl1
[flaml.automl.logger: 12-03 15:12:54] {2442} INFO -  at 61.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:54] {2258} INFO - iteration 165, current learner lrl1
[flaml.automl.logger: 12-03 15:12:54] {2442} INFO -  at 61.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:54] {2258} INFO - iteration 166, current learner lrl1
[flaml.automl.logger: 12-03 15:12:54] {2442} INFO -  at 61.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:54] {2258} INFO - iteration 167, current learner lgbm
[flaml.automl.logger: 12-03 15:12:55] {2442} INFO -  at 62.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:55] {2258} INFO - iteration 168, current learner lrl1
[flaml.automl.logger: 12-03 15:12:55] {2442} INFO -  at 62.6s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:55] {2258} INFO - iteration 169, current learner lrl1
[flaml.automl.logger: 12-03 15:12:55] {2442} INFO -  at 62.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:55] {2258} INFO - iteration 170, current learner lrl1
[flaml.automl.logger: 12-03 15:12:55] {2442} INFO -  at 62.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:55] {2258} INFO - iteration 171, current learner lgbm
[flaml.automl.logger: 12-03 15:12:55] {2442} INFO -  at 63.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:55] {2258} INFO - iteration 172, current learner lgbm
[flaml.automl.logger: 12-03 15:12:56] {2442} INFO -  at 63.9s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:56] {2258} INFO - iteration 173, current learner lgbm
[flaml.automl.logger: 12-03 15:12:56] {2442} INFO -  at 64.2s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:56] {2258} INFO - iteration 174, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:12:57] {2442} INFO -  at 64.6s,  estimator xgb_limitdepth's best error=0.0629,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:57] {2258} INFO - iteration 175, current learner lrl1
[flaml.automl.logger: 12-03 15:12:57] {2442} INFO -  at 64.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:57] {2258} INFO - iteration 176, current learner lrl1
[flaml.automl.logger: 12-03 15:12:57] {2442} INFO -  at 64.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:57] {2258} INFO - iteration 177, current learner lgbm
[flaml.automl.logger: 12-03 15:12:58] {2442} INFO -  at 65.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:58] {2258} INFO - iteration 178, current learner lrl1
[flaml.automl.logger: 12-03 15:12:58] {2442} INFO -  at 65.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:58] {2258} INFO - iteration 179, current learner lrl1
[flaml.automl.logger: 12-03 15:12:58] {2442} INFO -  at 66.1s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:58] {2258} INFO - iteration 180, current learner lgbm
[flaml.automl.logger: 12-03 15:12:59] {2442} INFO -  at 66.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:59] {2258} INFO - iteration 181, current learner lrl1
[flaml.automl.logger: 12-03 15:12:59] {2442} INFO -  at 66.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:59] {2258} INFO - iteration 182, current learner lrl1
[flaml.automl.logger: 12-03 15:12:59] {2442} INFO -  at 67.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:59] {2258} INFO - iteration 183, current learner lrl1
[flaml.automl.logger: 12-03 15:12:59] {2442} INFO -  at 67.1s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:12:59] {2258} INFO - iteration 184, current learner lgbm
[flaml.automl.logger: 12-03 15:13:00] {2442} INFO -  at 67.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:00] {2258} INFO - iteration 185, current learner lgbm
[flaml.automl.logger: 12-03 15:13:01] {2442} INFO -  at 68.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:01] {2258} INFO - iteration 186, current learner lgbm
[flaml.automl.logger: 12-03 15:13:01] {2442} INFO -  at 68.8s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:01] {2258} INFO - iteration 187, current learner lrl1
[flaml.automl.logger: 12-03 15:13:01] {2442} INFO -  at 69.0s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:01] {2258} INFO - iteration 188, current learner lgbm
[flaml.automl.logger: 12-03 15:13:02] {2442} INFO -  at 69.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:02] {2258} INFO - iteration 189, current learner lrl1
[flaml.automl.logger: 12-03 15:13:02] {2442} INFO -  at 69.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:02] {2258} INFO - iteration 190, current learner lgbm
[flaml.automl.logger: 12-03 15:13:02] {2442} INFO -  at 70.2s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:02] {2258} INFO - iteration 191, current learner lgbm
[flaml.automl.logger: 12-03 15:13:03] {2442} INFO -  at 70.6s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:03] {2258} INFO - iteration 192, current learner lrl1
[flaml.automl.logger: 12-03 15:13:03] {2442} INFO -  at 70.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:03] {2258} INFO - iteration 193, current learner lgbm
[flaml.automl.logger: 12-03 15:13:04] {2442} INFO -  at 71.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:04] {2258} INFO - iteration 194, current learner lrl1
[flaml.automl.logger: 12-03 15:13:04] {2442} INFO -  at 71.5s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:04] {2258} INFO - iteration 195, current learner lrl1
[flaml.automl.logger: 12-03 15:13:04] {2442} INFO -  at 71.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:04] {2258} INFO - iteration 196, current learner lrl1
[flaml.automl.logger: 12-03 15:13:04] {2442} INFO -  at 71.8s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:04] {2258} INFO - iteration 197, current learner lgbm
[flaml.automl.logger: 12-03 15:13:04] {2442} INFO -  at 72.1s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:04] {2258} INFO - iteration 198, current learner lgbm
[flaml.automl.logger: 12-03 15:13:05] {2442} INFO -  at 73.1s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:05] {2258} INFO - iteration 199, current learner lrl1
[flaml.automl.logger: 12-03 15:13:05] {2442} INFO -  at 73.3s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:05] {2258} INFO - iteration 200, current learner lrl1
[flaml.automl.logger: 12-03 15:13:06] {2442} INFO -  at 73.4s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:06] {2258} INFO - iteration 201, current learner lrl1
[flaml.automl.logger: 12-03 15:13:06] {2442} INFO -  at 73.6s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:06] {2258} INFO - iteration 202, current learner lrl1
[flaml.automl.logger: 12-03 15:13:06] {2442} INFO -  at 73.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:06] {2258} INFO - iteration 203, current learner lgbm
[flaml.automl.logger: 12-03 15:13:06] {2442} INFO -  at 74.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:06] {2258} INFO - iteration 204, current learner lgbm
[flaml.automl.logger: 12-03 15:13:07] {2442} INFO -  at 74.8s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:07] {2258} INFO - iteration 205, current learner lrl1
[flaml.automl.logger: 12-03 15:13:07] {2442} INFO -  at 74.9s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:07] {2258} INFO - iteration 206, current learner lrl1
[flaml.automl.logger: 12-03 15:13:07] {2442} INFO -  at 75.1s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:07] {2258} INFO - iteration 207, current learner lrl1
[flaml.automl.logger: 12-03 15:13:07] {2442} INFO -  at 75.2s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:07] {2258} INFO - iteration 208, current learner lrl1
[flaml.automl.logger: 12-03 15:13:07] {2442} INFO -  at 75.4s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:07] {2258} INFO - iteration 209, current learner lrl1
[flaml.automl.logger: 12-03 15:13:08] {2442} INFO -  at 75.5s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:08] {2258} INFO - iteration 210, current learner lrl1
[flaml.automl.logger: 12-03 15:13:08] {2442} INFO -  at 75.7s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:08] {2258} INFO - iteration 211, current learner lgbm
[flaml.automl.logger: 12-03 15:13:08] {2442} INFO -  at 76.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:08] {2258} INFO - iteration 212, current learner rf
[flaml.automl.logger: 12-03 15:13:08] {2442} INFO -  at 76.3s,  estimator rf's best error=0.0730,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:08] {2258} INFO - iteration 213, current learner lrl1
[flaml.automl.logger: 12-03 15:13:09] {2442} INFO -  at 76.4s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:09] {2258} INFO - iteration 214, current learner lrl1
[flaml.automl.logger: 12-03 15:13:09] {2442} INFO -  at 76.6s,  estimator lrl1's best error=0.0529, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:09] {2258} INFO - iteration 215, current learner lrl1
[flaml.automl.logger: 12-03 15:13:09] {2442} INFO -  at 76.7s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:09] {2258} INFO - iteration 216, current learner lrl1
[flaml.automl.logger: 12-03 15:13:09] {2442} INFO -  at 76.8s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:09] {2258} INFO - iteration 217, current learner lgbm
[flaml.automl.logger: 12-03 15:13:10] {2442} INFO -  at 77.6s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:10] {2258} INFO - iteration 218, current learner lrl1
[flaml.automl.logger: 12-03 15:13:10] {2442} INFO -  at 77.8s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:10] {2258} INFO - iteration 219, current learner lgbm
[flaml.automl.logger: 12-03 15:13:11] {2442} INFO -  at 78.4s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:11] {2258} INFO - iteration 220, current learner lgbm
[flaml.automl.logger: 12-03 15:13:11] {2442} INFO -  at 78.8s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:11] {2258} INFO - iteration 221, current learner lgbm
[flaml.automl.logger: 12-03 15:13:11] {2442} INFO -  at 79.2s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:11] {2258} INFO - iteration 222, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:12] {2442} INFO -  at 79.7s,  estimator extra_tree's best error=0.1008,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:12] {2258} INFO - iteration 223, current learner lgbm
[flaml.automl.logger: 12-03 15:13:12] {2442} INFO -  at 80.2s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:12] {2258} INFO - iteration 224, current learner lrl1
[flaml.automl.logger: 12-03 15:13:13] {2442} INFO -  at 80.4s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:13] {2258} INFO - iteration 225, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:13] {2442} INFO -  at 80.8s,  estimator extra_tree's best error=0.0931,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:13] {2258} INFO - iteration 226, current learner lgbm
[flaml.automl.logger: 12-03 15:13:14] {2442} INFO -  at 81.4s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:14] {2258} INFO - iteration 227, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:14] {2442} INFO -  at 81.7s,  estimator extra_tree's best error=0.0931,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:14] {2258} INFO - iteration 228, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:14] {2442} INFO -  at 82.2s,  estimator extra_tree's best error=0.0931,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:14] {2258} INFO - iteration 229, current learner lgbm
[flaml.automl.logger: 12-03 15:13:15] {2442} INFO -  at 82.7s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:15] {2258} INFO - iteration 230, current learner lrl1
[flaml.automl.logger: 12-03 15:13:15] {2442} INFO -  at 82.9s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:15] {2258} INFO - iteration 231, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:15] {2442} INFO -  at 83.2s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:15] {2258} INFO - iteration 232, current learner lrl1
[flaml.automl.logger: 12-03 15:13:15] {2442} INFO -  at 83.3s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:15] {2258} INFO - iteration 233, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:16] {2442} INFO -  at 83.8s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:16] {2258} INFO - iteration 234, current learner lrl1
[flaml.automl.logger: 12-03 15:13:16] {2442} INFO -  at 83.9s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:16] {2258} INFO - iteration 235, current learner lrl1
[flaml.automl.logger: 12-03 15:13:16] {2442} INFO -  at 84.1s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:16] {2258} INFO - iteration 236, current learner lrl1
[flaml.automl.logger: 12-03 15:13:16] {2442} INFO -  at 84.3s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:16] {2258} INFO - iteration 237, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:17] {2442} INFO -  at 84.8s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:17] {2258} INFO - iteration 238, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:18] {2442} INFO -  at 85.4s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:18] {2258} INFO - iteration 239, current learner lrl1
[flaml.automl.logger: 12-03 15:13:18] {2442} INFO -  at 85.6s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:18] {2258} INFO - iteration 240, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:18] {2442} INFO -  at 85.9s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:18] {2258} INFO - iteration 241, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:18] {2442} INFO -  at 86.2s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:18] {2258} INFO - iteration 242, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:19] {2442} INFO -  at 86.6s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:19] {2258} INFO - iteration 243, current learner lgbm
[flaml.automl.logger: 12-03 15:13:20] {2442} INFO -  at 87.4s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:20] {2258} INFO - iteration 244, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:20] {2442} INFO -  at 87.9s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:20] {2258} INFO - iteration 245, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:20] {2442} INFO -  at 88.2s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:20] {2258} INFO - iteration 246, current learner lrl1
[flaml.automl.logger: 12-03 15:13:21] {2442} INFO -  at 88.4s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:21] {2258} INFO - iteration 247, current learner rf
[flaml.automl.logger: 12-03 15:13:21] {2442} INFO -  at 88.9s,  estimator rf's best error=0.0706,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:21] {2258} INFO - iteration 248, current learner lrl1
[flaml.automl.logger: 12-03 15:13:21] {2442} INFO -  at 89.1s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:21] {2258} INFO - iteration 249, current learner rf
[flaml.automl.logger: 12-03 15:13:22] {2442} INFO -  at 89.6s,  estimator rf's best error=0.0706,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:22] {2258} INFO - iteration 250, current learner lgbm
[flaml.automl.logger: 12-03 15:13:22] {2442} INFO -  at 90.0s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:22] {2258} INFO - iteration 251, current learner lrl1
[flaml.automl.logger: 12-03 15:13:22] {2442} INFO -  at 90.1s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:22] {2258} INFO - iteration 252, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:23] {2442} INFO -  at 90.6s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:23] {2258} INFO - iteration 253, current learner lgbm
[flaml.automl.logger: 12-03 15:13:23] {2442} INFO -  at 91.2s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:23] {2258} INFO - iteration 254, current learner rf
[flaml.automl.logger: 12-03 15:13:24] {2442} INFO -  at 91.6s,  estimator rf's best error=0.0706,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:24] {2258} INFO - iteration 255, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:24] {2442} INFO -  at 91.9s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:24] {2258} INFO - iteration 256, current learner lrl1
[flaml.automl.logger: 12-03 15:13:24] {2442} INFO -  at 92.1s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:24] {2258} INFO - iteration 257, current learner lgbm
[flaml.automl.logger: 12-03 15:13:25] {2442} INFO -  at 92.5s,  estimator lgbm's best error=0.0528, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:25] {2258} INFO - iteration 258, current learner lrl1
[flaml.automl.logger: 12-03 15:13:25] {2442} INFO -  at 92.7s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:25] {2258} INFO - iteration 259, current learner rf
[flaml.automl.logger: 12-03 15:13:25] {2442} INFO -  at 93.2s,  estimator rf's best error=0.0706,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:25] {2258} INFO - iteration 260, current learner lrl1
[flaml.automl.logger: 12-03 15:13:25] {2442} INFO -  at 93.3s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:25] {2258} INFO - iteration 261, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:26] {2442} INFO -  at 93.8s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:26] {2258} INFO - iteration 262, current learner lrl1
[flaml.automl.logger: 12-03 15:13:26] {2442} INFO -  at 93.9s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:26] {2258} INFO - iteration 263, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:27] {2442} INFO -  at 94.4s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:27] {2258} INFO - iteration 264, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:27] {2442} INFO -  at 94.7s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:27] {2258} INFO - iteration 265, current learner rf
[flaml.automl.logger: 12-03 15:13:27] {2442} INFO -  at 95.3s,  estimator rf's best error=0.0706,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:27] {2258} INFO - iteration 266, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:28] {2442} INFO -  at 95.7s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:28] {2258} INFO - iteration 267, current learner lrl1
[flaml.automl.logger: 12-03 15:13:28] {2442} INFO -  at 95.9s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:28] {2258} INFO - iteration 268, current learner lrl1
[flaml.automl.logger: 12-03 15:13:28] {2442} INFO -  at 96.0s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:28] {2258} INFO - iteration 269, current learner lrl1
[flaml.automl.logger: 12-03 15:13:28] {2442} INFO -  at 96.2s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:28] {2258} INFO - iteration 270, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:29] {2442} INFO -  at 96.7s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:29] {2258} INFO - iteration 271, current learner lrl1
[flaml.automl.logger: 12-03 15:13:29] {2442} INFO -  at 96.9s,  estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:29] {2258} INFO - iteration 272, current learner rf
[flaml.automl.logger: 12-03 15:13:30] {2442} INFO -  at 97.4s,  estimator rf's best error=0.0706,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:30] {2258} INFO - iteration 273, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:30] {2442} INFO -  at 97.9s,  estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:30] {2258} INFO - iteration 274, current learner rf
[flaml.automl.logger: 12-03 15:13:31] {2442} INFO -  at 98.5s,  estimator rf's best error=0.0706,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:31] {2258} INFO - iteration 275, current learner rf
[flaml.automl.logger: 12-03 15:13:31] {2442} INFO -  at 99.0s,  estimator rf's best error=0.0706,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:31] {2258} INFO - iteration 276, current learner rf
[flaml.automl.logger: 12-03 15:13:32] {2442} INFO -  at 99.6s,  estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:32] {2258} INFO - iteration 277, current learner rf
[flaml.automl.logger: 12-03 15:13:32] {2442} INFO -  at 100.0s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:32] {2258} INFO - iteration 278, current learner rf
[flaml.automl.logger: 12-03 15:13:33] {2442} INFO -  at 100.7s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:33] {2258} INFO - iteration 279, current learner rf
[flaml.automl.logger: 12-03 15:13:33] {2442} INFO -  at 101.0s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:33] {2258} INFO - iteration 280, current learner rf
[flaml.automl.logger: 12-03 15:13:34] {2442} INFO -  at 101.7s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:34] {2258} INFO - iteration 281, current learner lrl1
[flaml.automl.logger: 12-03 15:13:34] {2442} INFO -  at 101.9s, estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:34] {2258} INFO - iteration 282, current learner rf
[flaml.automl.logger: 12-03 15:13:35] {2442} INFO -  at 102.5s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:35] {2258} INFO - iteration 283, current learner rf
[flaml.automl.logger: 12-03 15:13:35] {2442} INFO -  at 103.1s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:35] {2258} INFO - iteration 284, current learner rf
[flaml.automl.logger: 12-03 15:13:36] {2442} INFO -  at 103.7s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:36] {2258} INFO - iteration 285, current learner rf
[flaml.automl.logger: 12-03 15:13:36] {2442} INFO -  at 104.2s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:36] {2258} INFO - iteration 286, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:37] {2442} INFO -  at 104.5s, estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:37] {2258} INFO - iteration 287, current learner lrl1
[flaml.automl.logger: 12-03 15:13:37] {2442} INFO -  at 104.6s, estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:37] {2258} INFO - iteration 288, current learner lrl1
[flaml.automl.logger: 12-03 15:13:37] {2442} INFO -  at 104.7s, estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:37] {2258} INFO - iteration 289, current learner rf
[flaml.automl.logger: 12-03 15:13:37] {2442} INFO -  at 105.2s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:37] {2258} INFO - iteration 290, current learner rf
[flaml.automl.logger: 12-03 15:13:38] {2442} INFO -  at 105.6s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:38] {2258} INFO - iteration 291, current learner rf
[flaml.automl.logger: 12-03 15:13:38] {2442} INFO -  at 106.0s, estimator rf's best error=0.0579,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:38] {2258} INFO - iteration 292, current learner lrl1
[flaml.automl.logger: 12-03 15:13:38] {2442} INFO -  at 106.2s, estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:38] {2258} INFO - iteration 293, current learner rf
[flaml.automl.logger: 12-03 15:13:39] {2442} INFO -  at 106.8s, estimator rf's best error=0.0555,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:39] {2258} INFO - iteration 294, current learner lrl1
[flaml.automl.logger: 12-03 15:13:39] {2442} INFO -  at 107.0s, estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:39] {2258} INFO - iteration 295, current learner rf
[flaml.automl.logger: 12-03 15:13:40] {2442} INFO -  at 107.7s, estimator rf's best error=0.0555,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:40] {2258} INFO - iteration 296, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:40] {2442} INFO -  at 108.2s, estimator extra_tree's best error=0.0831,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:40] {2258} INFO - iteration 297, current learner rf
[flaml.automl.logger: 12-03 15:13:41] {2442} INFO -  at 108.6s, estimator rf's best error=0.0555,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:41] {2258} INFO - iteration 298, current learner lrl1
[flaml.automl.logger: 12-03 15:13:41] {2442} INFO -  at 108.7s, estimator lrl1's best error=0.0503, best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:41] {2258} INFO - iteration 299, current learner rf
[flaml.automl.logger: 12-03 15:13:42] {2442} INFO -  at 109.4s, estimator rf's best error=0.0555,   best estimator lrl1's best error=0.0503
[flaml.automl.logger: 12-03 15:13:42] {2685} INFO - retrain lrl1 for 0.0s
[flaml.automl.logger: 12-03 15:13:42] {2688} INFO - retrained model: LogisticRegression(C=np.float64(0.8319557582176255), n_jobs=-1, penalty='l1',
                   solver='saga')
[flaml.automl.logger: 12-03 15:13:42] {1985} INFO - fit succeeded
[flaml.automl.logger: 12-03 15:13:42] {1986} INFO - Time taken to find the best model: 76.68833303451538</code></pre>
</div>
</div>
</section>

<section id="section-3" class="title-slide slide level1 center">
<h1></h1>
<div id="cell-77" class="cell" data-execution_count="40">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb53-1"><a href=""></a>automl.model.estimator</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="40">
<style>#sk-container-id-5 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-5 {
  color: var(--sklearn-color-text);
}

#sk-container-id-5 pre {
  padding: 0;
}

#sk-container-id-5 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-5 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-5 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-5 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-5 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-5 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-5 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-5 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-5 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-5 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-5 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-5 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-5 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-5 div.sk-label label.sk-toggleable__label,
#sk-container-id-5 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-5 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-5 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-5 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-5 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-5 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-5 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-5 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-5 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(C=np.float64(0.8319557582176255), n_jobs=-1, penalty='l1',
                   solver='saga')</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked=""><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;LogisticRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>LogisticRegression(C=np.float64(0.8319557582176255), n_jobs=-1, penalty='l1',
                   solver='saga')</pre></div> </div></div></div></div>
</div>
</div>
<div id="cell-78" class="cell" data-execution_count="41">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb54-1"><a href=""></a>metrics.accuracy_score(y_test, y_pred)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>0.935672514619883</code></pre>
</div>
</div>
</section>

<section id="setting-the-budget" class="title-slide slide level1 center">
<h1>Setting the budget</h1>
<div id="cell-80" class="cell" data-execution_count="42">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb56-1"><a href=""></a>automl, y_pred <span class="op">=</span> auto_ml(<span class="dv">100</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[flaml.automl.logger: 12-03 15:13:42] {1728} INFO - task = classification
[flaml.automl.logger: 12-03 15:13:42] {1739} INFO - Evaluation method: cv
[flaml.automl.logger: 12-03 15:13:42] {1838} INFO - Minimizing error metric: 1-accuracy
[flaml.automl.logger: 12-03 15:13:42] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'lrl1']
[flaml.automl.logger: 12-03 15:13:42] {2258} INFO - iteration 0, current learner lgbm
[flaml.automl.logger: 12-03 15:13:42] {2393} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.
[flaml.automl.logger: 12-03 15:13:42] {2442} INFO -  at 0.3s,   estimator lgbm's best error=0.1181, best estimator lgbm's best error=0.1181
[flaml.automl.logger: 12-03 15:13:42] {2258} INFO - iteration 1, current learner lgbm
[flaml.automl.logger: 12-03 15:13:42] {2442} INFO -  at 0.5s,   estimator lgbm's best error=0.1181, best estimator lgbm's best error=0.1181
[flaml.automl.logger: 12-03 15:13:42] {2258} INFO - iteration 2, current learner lgbm
[flaml.automl.logger: 12-03 15:13:42] {2442} INFO -  at 0.6s,   estimator lgbm's best error=0.0955, best estimator lgbm's best error=0.0955
[flaml.automl.logger: 12-03 15:13:42] {2258} INFO - iteration 3, current learner rf
[flaml.automl.logger: 12-03 15:13:43] {2442} INFO -  at 1.0s,   estimator rf's best error=0.0781,   best estimator rf's best error=0.0781
[flaml.automl.logger: 12-03 15:13:43] {2258} INFO - iteration 4, current learner lgbm
[flaml.automl.logger: 12-03 15:13:43] {2442} INFO -  at 1.3s,   estimator lgbm's best error=0.0831, best estimator rf's best error=0.0781
[flaml.automl.logger: 12-03 15:13:43] {2258} INFO - iteration 5, current learner lgbm
[flaml.automl.logger: 12-03 15:13:43] {2442} INFO -  at 1.5s,   estimator lgbm's best error=0.0831, best estimator rf's best error=0.0781
[flaml.automl.logger: 12-03 15:13:43] {2258} INFO - iteration 6, current learner lgbm
[flaml.automl.logger: 12-03 15:13:44] {2442} INFO -  at 1.9s,   estimator lgbm's best error=0.0730, best estimator lgbm's best error=0.0730
[flaml.automl.logger: 12-03 15:13:44] {2258} INFO - iteration 7, current learner lgbm
[flaml.automl.logger: 12-03 15:13:44] {2442} INFO -  at 2.5s,   estimator lgbm's best error=0.0655, best estimator lgbm's best error=0.0655
[flaml.automl.logger: 12-03 15:13:44] {2258} INFO - iteration 8, current learner lgbm
[flaml.automl.logger: 12-03 15:13:45] {2442} INFO -  at 3.1s,   estimator lgbm's best error=0.0655, best estimator lgbm's best error=0.0655
[flaml.automl.logger: 12-03 15:13:45] {2258} INFO - iteration 9, current learner lgbm
[flaml.automl.logger: 12-03 15:13:45] {2442} INFO -  at 3.7s,   estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:45] {2258} INFO - iteration 10, current learner rf
[flaml.automl.logger: 12-03 15:13:46] {2442} INFO -  at 4.0s,   estimator rf's best error=0.0781,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:46] {2258} INFO - iteration 11, current learner xgboost
[flaml.automl.logger: 12-03 15:13:46] {2442} INFO -  at 4.3s,   estimator xgboost's best error=0.1006,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:46] {2258} INFO - iteration 12, current learner rf
[flaml.automl.logger: 12-03 15:13:47] {2442} INFO -  at 4.8s,   estimator rf's best error=0.0756,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:47] {2258} INFO - iteration 13, current learner xgboost
[flaml.automl.logger: 12-03 15:13:47] {2442} INFO -  at 5.1s,   estimator xgboost's best error=0.1006,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:47] {2258} INFO - iteration 14, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:47] {2442} INFO -  at 5.5s,   estimator extra_tree's best error=0.1108,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:47] {2258} INFO - iteration 15, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:13:48] {2442} INFO -  at 6.0s,   estimator xgb_limitdepth's best error=0.0655,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:48] {2258} INFO - iteration 16, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:13:48] {2442} INFO -  at 6.5s,   estimator xgb_limitdepth's best error=0.0630,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:48] {2258} INFO - iteration 17, current learner sgd
[flaml.automl.logger: 12-03 15:13:48] {2442} INFO -  at 6.7s,   estimator sgd's best error=0.0680,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:48] {2258} INFO - iteration 18, current learner xgboost
[flaml.automl.logger: 12-03 15:13:49] {2442} INFO -  at 7.0s,   estimator xgboost's best error=0.0705,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:49] {2258} INFO - iteration 19, current learner sgd
[flaml.automl.logger: 12-03 15:13:49] {2442} INFO -  at 7.2s,   estimator sgd's best error=0.0680,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:49] {2258} INFO - iteration 20, current learner lgbm
[flaml.automl.logger: 12-03 15:13:49] {2442} INFO -  at 7.8s,   estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:49] {2258} INFO - iteration 21, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:13:50] {2442} INFO -  at 8.2s,   estimator xgb_limitdepth's best error=0.0630,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:50] {2258} INFO - iteration 22, current learner extra_tree
[flaml.automl.logger: 12-03 15:13:50] {2442} INFO -  at 8.6s,   estimator extra_tree's best error=0.1107,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:50] {2258} INFO - iteration 23, current learner sgd
[flaml.automl.logger: 12-03 15:13:50] {2442} INFO -  at 8.7s,   estimator sgd's best error=0.0655,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:50] {2258} INFO - iteration 24, current learner lrl1
[flaml.automl.logger: 12-03 15:13:51] {2442} INFO -  at 8.8s,   estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:51] {2258} INFO - iteration 25, current learner lgbm
[flaml.automl.logger: 12-03 15:13:51] {2442} INFO -  at 9.7s,   estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:51] {2258} INFO - iteration 26, current learner lgbm
[flaml.automl.logger: 12-03 15:13:52] {2442} INFO -  at 10.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:52] {2258} INFO - iteration 27, current learner lrl1
[flaml.automl.logger: 12-03 15:13:52] {2442} INFO -  at 10.1s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:52] {2258} INFO - iteration 28, current learner lrl1
[flaml.automl.logger: 12-03 15:13:52] {2442} INFO -  at 10.3s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:52] {2258} INFO - iteration 29, current learner xgboost
[flaml.automl.logger: 12-03 15:13:52] {2442} INFO -  at 10.5s,  estimator xgboost's best error=0.0705,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:52] {2258} INFO - iteration 30, current learner lrl1
[flaml.automl.logger: 12-03 15:13:52] {2442} INFO -  at 10.7s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:52] {2258} INFO - iteration 31, current learner lrl1
[flaml.automl.logger: 12-03 15:13:53] {2442} INFO -  at 10.9s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:53] {2258} INFO - iteration 32, current learner lrl1
[flaml.automl.logger: 12-03 15:13:53] {2442} INFO -  at 11.0s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:53] {2258} INFO - iteration 33, current learner lgbm
[flaml.automl.logger: 12-03 15:13:53] {2442} INFO -  at 11.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:53] {2258} INFO - iteration 34, current learner lgbm
[flaml.automl.logger: 12-03 15:13:54] {2442} INFO -  at 12.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:54] {2258} INFO - iteration 35, current learner lgbm
[flaml.automl.logger: 12-03 15:13:55] {2442} INFO -  at 13.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:55] {2258} INFO - iteration 36, current learner lrl1
[flaml.automl.logger: 12-03 15:13:55] {2442} INFO -  at 13.5s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:55] {2258} INFO - iteration 37, current learner lgbm
[flaml.automl.logger: 12-03 15:13:56] {2442} INFO -  at 13.8s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:56] {2258} INFO - iteration 38, current learner xgboost
[flaml.automl.logger: 12-03 15:13:56] {2442} INFO -  at 14.1s,  estimator xgboost's best error=0.0656,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:56] {2258} INFO - iteration 39, current learner lrl1
[flaml.automl.logger: 12-03 15:13:56] {2442} INFO -  at 14.3s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:56] {2258} INFO - iteration 40, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:13:57] {2442} INFO -  at 14.8s,  estimator xgb_limitdepth's best error=0.0630,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:57] {2258} INFO - iteration 41, current learner sgd
[flaml.automl.logger: 12-03 15:13:57] {2442} INFO -  at 15.1s,  estimator sgd's best error=0.0655,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:57] {2258} INFO - iteration 42, current learner rf
[flaml.automl.logger: 12-03 15:13:57] {2442} INFO -  at 15.5s,  estimator rf's best error=0.0731,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:57] {2258} INFO - iteration 43, current learner sgd
[flaml.automl.logger: 12-03 15:13:57] {2442} INFO -  at 15.6s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:57] {2258} INFO - iteration 44, current learner sgd
[flaml.automl.logger: 12-03 15:13:58] {2442} INFO -  at 15.9s,  estimator sgd's best error=0.0554,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:58] {2258} INFO - iteration 45, current learner lgbm
[flaml.automl.logger: 12-03 15:13:58] {2442} INFO -  at 16.1s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:58] {2258} INFO - iteration 46, current learner sgd
[flaml.automl.logger: 12-03 15:13:58] {2442} INFO -  at 16.2s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:58] {2258} INFO - iteration 47, current learner lrl1
[flaml.automl.logger: 12-03 15:13:58] {2442} INFO -  at 16.3s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:58] {2258} INFO - iteration 48, current learner sgd
[flaml.automl.logger: 12-03 15:13:58] {2442} INFO -  at 16.4s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:58] {2258} INFO - iteration 49, current learner xgboost
[flaml.automl.logger: 12-03 15:13:58] {2442} INFO -  at 16.7s,  estimator xgboost's best error=0.0656,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:58] {2258} INFO - iteration 50, current learner sgd
[flaml.automl.logger: 12-03 15:13:59] {2442} INFO -  at 16.8s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:13:59] {2258} INFO - iteration 51, current learner lgbm
[flaml.automl.logger: 12-03 15:14:00] {2442} INFO -  at 18.3s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:00] {2258} INFO - iteration 52, current learner sgd
[flaml.automl.logger: 12-03 15:14:00] {2442} INFO -  at 18.4s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:00] {2258} INFO - iteration 53, current learner lrl1
[flaml.automl.logger: 12-03 15:14:00] {2442} INFO -  at 18.5s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:00] {2258} INFO - iteration 54, current learner xgboost
[flaml.automl.logger: 12-03 15:14:01] {2442} INFO -  at 18.8s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:01] {2258} INFO - iteration 55, current learner xgboost
[flaml.automl.logger: 12-03 15:14:01] {2442} INFO -  at 19.3s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:01] {2258} INFO - iteration 56, current learner lgbm
[flaml.automl.logger: 12-03 15:14:02] {2442} INFO -  at 20.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:02] {2258} INFO - iteration 57, current learner lgbm
[flaml.automl.logger: 12-03 15:14:02] {2442} INFO -  at 20.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:02] {2258} INFO - iteration 58, current learner sgd
[flaml.automl.logger: 12-03 15:14:03] {2442} INFO -  at 20.8s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:03] {2258} INFO - iteration 59, current learner rf
[flaml.automl.logger: 12-03 15:14:03] {2442} INFO -  at 21.1s,  estimator rf's best error=0.0731,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:03] {2258} INFO - iteration 60, current learner xgboost
[flaml.automl.logger: 12-03 15:14:03] {2442} INFO -  at 21.4s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:03] {2258} INFO - iteration 61, current learner sgd
[flaml.automl.logger: 12-03 15:14:03] {2442} INFO -  at 21.5s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:03] {2258} INFO - iteration 62, current learner lgbm
[flaml.automl.logger: 12-03 15:14:04] {2442} INFO -  at 22.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:04] {2258} INFO - iteration 63, current learner sgd
[flaml.automl.logger: 12-03 15:14:04] {2442} INFO -  at 22.2s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:04] {2258} INFO - iteration 64, current learner lgbm
[flaml.automl.logger: 12-03 15:14:04] {2442} INFO -  at 22.7s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:04] {2258} INFO - iteration 65, current learner sgd
[flaml.automl.logger: 12-03 15:14:05] {2442} INFO -  at 22.9s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:05] {2258} INFO - iteration 66, current learner sgd
[flaml.automl.logger: 12-03 15:14:05] {2442} INFO -  at 22.9s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:05] {2258} INFO - iteration 67, current learner lgbm
[flaml.automl.logger: 12-03 15:14:05] {2442} INFO -  at 23.2s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:05] {2258} INFO - iteration 68, current learner xgb_limitdepth
[flaml.automl.logger: 12-03 15:14:06] {2442} INFO -  at 23.8s,  estimator xgb_limitdepth's best error=0.0629,   best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:06] {2258} INFO - iteration 69, current learner sgd
[flaml.automl.logger: 12-03 15:14:06] {2442} INFO -  at 23.8s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:06] {2258} INFO - iteration 70, current learner sgd
[flaml.automl.logger: 12-03 15:14:06] {2442} INFO -  at 23.9s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:06] {2258} INFO - iteration 71, current learner lgbm
[flaml.automl.logger: 12-03 15:14:07] {2442} INFO -  at 24.8s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:07] {2258} INFO - iteration 72, current learner sgd
[flaml.automl.logger: 12-03 15:14:07] {2442} INFO -  at 24.9s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:07] {2258} INFO - iteration 73, current learner sgd
[flaml.automl.logger: 12-03 15:14:07] {2442} INFO -  at 25.0s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:07] {2258} INFO - iteration 74, current learner sgd
[flaml.automl.logger: 12-03 15:14:07] {2442} INFO -  at 25.0s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:07] {2258} INFO - iteration 75, current learner lrl1
[flaml.automl.logger: 12-03 15:14:07] {2442} INFO -  at 25.2s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:07] {2258} INFO - iteration 76, current learner sgd
[flaml.automl.logger: 12-03 15:14:07] {2442} INFO -  at 25.2s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:07] {2258} INFO - iteration 77, current learner lrl1
[flaml.automl.logger: 12-03 15:14:07] {2442} INFO -  at 25.4s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:07] {2258} INFO - iteration 78, current learner lgbm
[flaml.automl.logger: 12-03 15:14:08] {2442} INFO -  at 25.9s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:08] {2258} INFO - iteration 79, current learner lgbm
[flaml.automl.logger: 12-03 15:14:08] {2442} INFO -  at 26.4s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:08] {2258} INFO - iteration 80, current learner lrl1
[flaml.automl.logger: 12-03 15:14:08] {2442} INFO -  at 26.5s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:08] {2258} INFO - iteration 81, current learner sgd
[flaml.automl.logger: 12-03 15:14:08] {2442} INFO -  at 26.6s,  estimator sgd's best error=0.0528,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:08] {2258} INFO - iteration 82, current learner lgbm
[flaml.automl.logger: 12-03 15:14:09] {2442} INFO -  at 27.0s,  estimator lgbm's best error=0.0528, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:09] {2258} INFO - iteration 83, current learner lrl1
[flaml.automl.logger: 12-03 15:14:09] {2442} INFO -  at 27.2s,  estimator lrl1's best error=0.0554, best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:09] {2258} INFO - iteration 84, current learner xgboost
[flaml.automl.logger: 12-03 15:14:09] {2442} INFO -  at 27.5s,  estimator xgboost's best error=0.0629,  best estimator lgbm's best error=0.0528
[flaml.automl.logger: 12-03 15:14:09] {2258} INFO - iteration 85, current learner sgd
[flaml.automl.logger: 12-03 15:14:09] {2442} INFO -  at 27.5s,  estimator sgd's best error=0.0503,  best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:09] {2258} INFO - iteration 86, current learner sgd
[flaml.automl.logger: 12-03 15:14:09] {2442} INFO -  at 27.6s,  estimator sgd's best error=0.0503,  best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:09] {2258} INFO - iteration 87, current learner lrl1
[flaml.automl.logger: 12-03 15:14:09] {2442} INFO -  at 27.8s,  estimator lrl1's best error=0.0554, best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:09] {2258} INFO - iteration 88, current learner sgd
[flaml.automl.logger: 12-03 15:14:10] {2442} INFO -  at 27.8s,  estimator sgd's best error=0.0503,  best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:10] {2258} INFO - iteration 89, current learner sgd
[flaml.automl.logger: 12-03 15:14:10] {2442} INFO -  at 27.9s,  estimator sgd's best error=0.0503,  best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:10] {2258} INFO - iteration 90, current learner sgd
[flaml.automl.logger: 12-03 15:14:10] {2442} INFO -  at 27.9s,  estimator sgd's best error=0.0503,  best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:10] {2258} INFO - iteration 91, current learner rf
[flaml.automl.logger: 12-03 15:14:10] {2442} INFO -  at 28.5s,  estimator rf's best error=0.0731,   best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:10] {2258} INFO - iteration 92, current learner lrl1
[flaml.automl.logger: 12-03 15:14:10] {2442} INFO -  at 28.7s,  estimator lrl1's best error=0.0554, best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:10] {2258} INFO - iteration 93, current learner sgd
[flaml.automl.logger: 12-03 15:14:10] {2442} INFO -  at 28.7s,  estimator sgd's best error=0.0503,  best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:10] {2258} INFO - iteration 94, current learner lrl1
[flaml.automl.logger: 12-03 15:14:11] {2442} INFO -  at 28.9s,  estimator lrl1's best error=0.0529, best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:11] {2258} INFO - iteration 95, current learner sgd
[flaml.automl.logger: 12-03 15:14:11] {2442} INFO -  at 28.9s,  estimator sgd's best error=0.0503,  best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:11] {2258} INFO - iteration 96, current learner sgd
[flaml.automl.logger: 12-03 15:14:11] {2442} INFO -  at 29.0s,  estimator sgd's best error=0.0503,  best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:11] {2258} INFO - iteration 97, current learner lgbm
[flaml.automl.logger: 12-03 15:14:11] {2442} INFO -  at 29.6s,  estimator lgbm's best error=0.0528, best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:11] {2258} INFO - iteration 98, current learner lrl1
[flaml.automl.logger: 12-03 15:14:11] {2442} INFO -  at 29.8s,  estimator lrl1's best error=0.0529, best estimator sgd's best error=0.0503
[flaml.automl.logger: 12-03 15:14:12] {2258} INFO - iteration 99, current learner sgd
[flaml.automl.logger: 12-03 15:14:12] {2442} INFO -  at 29.8s,  estimator sgd's best error=0.0478,  best estimator sgd's best error=0.0478
[flaml.automl.logger: 12-03 15:14:12] {2685} INFO - retrain sgd for 0.0s
[flaml.automl.logger: 12-03 15:14:12] {2688} INFO - retrained model: SGDClassifier(alpha=np.float64(1.9436500793418987e-05),
              eta0=np.float64(0.07635073555144868), learning_rate='invscaling',
              loss=np.str_('log_loss'), n_jobs=-1, penalty=np.str_('l2'),
              power_t=1e-05, tol=0.0001)
[flaml.automl.logger: 12-03 15:14:12] {1985} INFO - fit succeeded
[flaml.automl.logger: 12-03 15:14:12] {1986} INFO - Time taken to find the best model: 29.82857084274292</code></pre>
</div>
</div>
<div id="cell-81" class="cell" data-execution_count="43">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb58-1"><a href=""></a>metrics.accuracy_score(y_test, y_pred)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>0.9298245614035088</code></pre>
</div>
</div>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Matteo Francia - Machine Learning and Data Mining (Module 2) - A.Y. 2025/26</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': true,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>